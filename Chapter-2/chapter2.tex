%==============================================================================
% Chapter 2: Intelligent Inference in Intermittent Systems
% From Ensemble Learning to Efficient Communication
%==============================================================================

\chapter{Intelligent Inference in Intermittent Systems: From Ensemble Learning to Efficient Communication}
\label{ch:intelligent-inference}

%==============================================================================
\section{Introduction}
\label{sec:ch2-introduction}

The previous chapter established the fundamental challenges and opportunities of intermittent computing systems, demonstrating how energy harvesting can enable sustainable, battery-free operation for Internet of Things (IoT) devices. We explored the architectural innovations necessary to maintain computational progress despite frequent power failures, including non-volatile processors, checkpoint mechanisms, and task-based programming models. However, while these foundational techniques enable basic computation under intermittent power, they do not address a critical question facing modern IoT deployments: how can intermittent systems perform sophisticated machine learning inference tasks that typically require coordinated operation across multiple distributed sensors?

This chapter addresses this challenge by presenting a comprehensive approach to enabling intelligent inference on energy-harvesting wireless sensor networks (EH-WSNs). The work spans two interconnected contributions that together enable practical distributed inference on intermittent devices. First, we introduce Origin, a system that leverages ensemble learning to coordinate inference across multiple intermittent nodes despite their unreliable power availability. Origin achieves 83.88\% classification accuracy on human activity recognition tasks---surpassing battery-powered baselines despite operating entirely on harvested energy. Second, we present Seeker, which addresses Origin's communication bottleneck through intelligent data compression using coresets. By providing an efficient fallback path for incomplete inferences, Seeker increases the effective inference completion rate while maintaining 87.05\% classification accuracy on MHEALTH---approximately 7\% improvement over Origin alone.

\subsection{The Challenge of Distributed Inference on Intermittent Systems}

Modern IoT applications increasingly demand real-time inference capabilities for tasks such as human activity recognition (HAR), predictive maintenance, health monitoring, and environmental sensing~\cite{AppleECG,AppleFall,Google-Assistant-Watch}. These applications typically rely on deep neural networks (DNNs) that process data from multiple distributed sensors to achieve high accuracy. For instance, a body area network for HAR might include accelerometers and gyroscopes positioned at the wrist, ankle, and chest, each capturing different aspects of human movement that collectively enable accurate activity classification.

Traditionally, such systems have addressed the computational demands of DNN inference by transmitting raw sensor data to cloud servers or nearby edge devices with sufficient computational resources. However, this approach faces fundamental limitations in energy-harvesting scenarios. Communication is notoriously power-hungry---transmitting raw sensor data can consume 10-100$\times$ more energy than local computation~\cite{spendthrift,ResiRCA}. For devices powered by harvested energy measured in microwatts, continuous data transmission is simply infeasible. Moreover, the sporadic nature of harvested energy means that sensors may lose power mid-transmission, corrupting entire data packets and wasting precious energy.

Recent advances in edge computing have proposed performing inference directly on sensor nodes to reduce communication overhead~\cite{IntBeyondEdge,chinchilla}. While this approach shows promise for battery-powered systems, it faces unique challenges in intermittent computing environments. Consider a scenario where multiple energy-harvesting sensors collaborate for distributed inference. The fundamental challenge lies in coordination---ensemble learning typically requires all participating nodes to complete their inference tasks synchronously. In EH-WSNs, the probability that all nodes have sufficient energy simultaneously is vanishingly small. Our experiments show that only 1\% of inference attempts succeed when requiring all three sensors to operate concurrently. Even when individual nodes attempt inference, the DNN computation may exceed available energy, causing the node to fail mid-inference. Without careful management, this results in wasted energy with no useful output. Furthermore, when local inference fails due to insufficient energy, nodes must still communicate something useful to maintain system operation. Transmitting raw data is prohibitively expensive, yet dropping samples entirely degrades accuracy unacceptably.

The temporal dynamics of human activities and many sensing phenomena add another layer of complexity. Human activities exhibit temporal continuity---walking typically continues for multiple steps, machinery degradation progresses gradually. Intermittent systems must exploit this continuity to maintain accuracy despite missing samples, a challenge that traditional inference approaches do not address.

\subsection{Our Approach: From Ensemble Coordination to Efficient Communication}

This chapter presents a systematic approach to addressing these challenges through two complementary systems that together enable practical distributed inference on intermittent devices.

\textbf{Origin: Ensemble Learning for Intermittent Inference.} Our first contribution introduces intelligent scheduling and adaptive ensemble learning specifically designed for EH-WSNs. Origin makes several key innovations that work synergistically to overcome the challenges of intermittent operation. The activity-aware scheduling algorithm anticipates the next likely activity and activates the sensor most capable of accurately classifying it, improving both energy efficiency and accuracy. Rather than treating all sensors equally, Origin recognizes that different sensors excel at detecting different activities---a wrist sensor may be ideal for detecting writing motions while an ankle sensor better captures walking patterns. The extended round-robin scheduling policy provides sensors with sufficient energy accumulation time between inference attempts, increasing completion rates from 10\% to 28\%. This seemingly simple innovation proves critical, as it allows sensors to harvest enough energy for complete inference rather than repeatedly failing with partial attempts. The adaptive confidence matrix dynamically weights each sensor's contribution based on its historical accuracy for different activities, enabling robust ensemble decisions even when some sensors cannot participate. Finally, the temporal recall mechanism exploits activity continuity by reusing recent classification results when sensors lack energy for new inferences, maintaining system responsiveness even during energy-scarce periods.

\textbf{Seeker: Enhancing Communication Efficiency.} Our second contribution addresses Origin's limitation by introducing intelligent fallback mechanisms when local inference cannot complete. Seeker's key insight is that when a sensor cannot complete inference locally, it can still contribute by transmitting a compressed representation that preserves essential features. The system introduces activity-aware coreset construction that dynamically selects representative data points based on the current activity context, achieving 8.9$\times$ compression while preserving classification accuracy. The recoverable coreset design enables high-fidelity reconstruction of original sensor data from compressed representations, supporting accurate inference at the host device. A hierarchical decision framework adaptively chooses between local inference, coreset transmission, or result reuse based on available energy and data characteristics. To make these techniques practical, Seeker includes hardware acceleration for coreset construction, making compression feasible within tight energy budgets through specialized non-volatile processing units.

\subsection{Contributions and Chapter Organization}

This chapter makes the following technical contributions to intermittent inference systems:

\begin{enumerate}[leftmargin=*]
\item \textbf{A comprehensive framework for distributed inference on intermittent systems} that addresses both coordination challenges through ensemble learning and communication efficiency through intelligent compression (Sections~\ref{sec:ch2-system-architecture} and \ref{sec:ch2-problem-formulation}).

\item \textbf{Novel scheduling and ensemble learning algorithms} specifically designed for intermittent operation, including activity-aware scheduling and adaptive confidence weighting that maintain high accuracy despite unreliable node availability (Section~\ref{sec:ch2-origin}).

\item \textbf{Innovative compression techniques based on coreset theory} that preserve critical features while achieving nearly order-of-magnitude reductions in communication volume, with hardware support for energy-efficient implementation (Section~\ref{sec:ch2-seeker}).

\item \textbf{Extensive empirical evaluation} on real-world datasets demonstrating the effectiveness of our approach across different energy harvesting scenarios and application domains (Section~\ref{sec:ch2-evaluation}).
\end{enumerate}

The remainder of this chapter is organized as follows. Section~\ref{sec:ch2-background} provides background on energy harvesting systems, ensemble learning, and coreset theory. Section~\ref{sec:ch2-system-architecture} presents our system architecture and formally defines the problem we address. Sections~\ref{sec:ch2-origin} and \ref{sec:ch2-seeker} detail the Origin and Seeker systems respectively. Section~\ref{sec:ch2-evaluation} presents our comprehensive evaluation, and Section~\ref{sec:ch2-conclusion} concludes with insights that motivate the next chapter on training models for intermittent deployment.

%==============================================================================
\section{Background and Related Work}
\label{sec:ch2-background}

This section provides the technical foundation for understanding intelligent inference on intermittent systems. We first review energy harvesting technologies and their implications for computation, then discuss DNN inference at the edge, and finally introduce the theoretical foundations of ensemble learning and coreset-based compression that underpin our approach.

\subsection{Energy Harvesting and Intermittent Computing}

Energy harvesting (EH) technologies convert ambient energy sources---such as solar, thermal, kinetic, or RF energy---into electrical power for computational devices~\cite{IntermittentChallange,NVPMicro}. While EH promises battery-free operation and improved sustainability for the trillions of IoT devices expected by 2030, it presents fundamental challenges for system design.

The power availability from harvested sources is both scarce and highly variable. Indoor solar panels typically generate 10-100 $\mu$W/cm$^2$, while kinetic energy harvesters produce 1-10 $\mu$W depending on movement patterns~\cite{EHSurvey}. This is orders of magnitude below the power requirements of traditional computing systems, necessitating radical rethinking of computational approaches. Energy harvesting systems experience frequent power failures when energy demand exceeds supply. Without careful management, these failures cause complete loss of computational state, forcing applications to restart from the beginning. Recent work on non-volatile processors (NVPs)~\cite{NVPMa,ResiRCA} addresses this through hardware that automatically preserves state across power failures, enabling computational progress despite intermittent operation.

While capacitors can buffer harvested energy, their limited capacity (typically 10-100 $\mu$F) means they can only sustain computation for milliseconds to seconds. Larger capacitors increase system size and cost while suffering from leakage that wastes precious harvested energy. This motivates techniques that can operate with minimal energy storage. Moreover, harvested energy varies dramatically across both space and time. A wrist-worn kinetic harvester generates power only during arm movement, while a chest-mounted solar harvester depends on clothing and body position. This heterogeneity complicates coordination in distributed systems where different nodes have different energy availability patterns.

\subsection{Deep Neural Network Inference at the Edge}

The success of deep learning has driven demand for intelligent edge devices capable of real-time inference. However, DNN inference poses significant challenges for resource-constrained devices. Modern DNNs for tasks like HAR require millions of multiply-accumulate (MAC) operations per inference. For example, the CNN architectures used in our work require 70+ million MACs per classification, translating to substantial energy consumption even on efficient hardware. DNNs have large memory footprints, with models typically requiring megabytes of storage for weights and activations. This exceeds the capacity of ultra-low-power microcontrollers, necessitating techniques like quantization and pruning to reduce model size~\cite{netadapt,EAPruning}. Many edge applications require real-time or near-real-time inference. Human activity recognition, for instance, must classify activities within hundreds of milliseconds to enable responsive applications. This conflicts with the slow energy accumulation in harvesting systems.

Recent work has proposed various approaches to enable DNN inference on edge devices. Model compression techniques including pruning, quantization, and knowledge distillation reduce model size and computational requirements~\cite{netadapt,drq-isca2020}. While effective for battery-powered devices, these techniques alone cannot address the fundamental unreliability of intermittent power. Computation partitioning approaches split DNN execution between edge and cloud~\cite{kang2017neurosurgeon,infocommDNNpart}. These systems optimize the partition point to minimize energy or latency but assume reliable network connectivity and sufficient power for communication---assumptions that fail in EH scenarios. Incremental inference methods designed specifically for intermittent systems~\cite{chinchilla,IntBeyondEdge} use checkpointing to preserve partial results across power failures. While these enable eventual completion of inference tasks, they do not address coordination challenges in distributed systems.

\subsection{Ensemble Learning Fundamentals}

Ensemble learning combines predictions from multiple models to achieve better performance than any individual model~\cite{PolikarEnsemble}. This approach is particularly relevant for distributed sensor networks where different sensors capture complementary information. The theoretical foundation of ensemble methods leverages the principle that diverse weak learners can be combined to form a strong learner. For classification tasks, if individual classifiers have error rates better than random guessing and make independent errors, their ensemble can achieve arbitrarily low error rates as the number of classifiers increases.

Common aggregation strategies include majority voting, weighted voting, and stacking. The choice of aggregation method depends on the relative expertise of individual models and the availability of validation data for learning combination weights. In sensor networks, diversity arises naturally from different sensor modalities, positions, and viewing angles. For example, a wrist-worn accelerometer excels at detecting arm movements while an ankle sensor better captures leg motion. However, traditional ensemble learning assumes all models can participate reliably---an assumption violated in intermittent systems where node availability is unpredictable. Our Origin system addresses this challenge through adaptive weighting that accounts for varying node participation.

\subsection{Coreset Theory and Applications}

Coresets, originating from computational geometry, provide a principled approach to data reduction that preserves essential properties for specific computational tasks~\cite{bachem2015coresets}. Formally, a coreset $S$ of a dataset $D$ is a small weighted subset such that for a specific query space $Q$ and error parameter $\epsilon$, the query results on $S$ approximate those on $D$ within a $(1 + \epsilon)$ factor. Common construction approaches include importance sampling, where points are selected with probability proportional to their contribution to the objective function, and clustering-based methods that select representative points from data clusters~\cite{Ting-He-ArXiv}.

For many problems, coresets of size $O(k/\epsilon^2)$ suffice to preserve solution quality, where $k$ is a problem-specific parameter and $\epsilon$ is the approximation error. This represents exponential compression for high-dimensional data. Recent work~\cite{Ting-He-IEEE} has applied coresets to sensor data compression, showing significant size reductions while preserving classification accuracy. However, existing approaches do not consider the unique constraints of intermittent systems, including energy limitations and the need for incremental construction. Our Seeker system extends coreset theory with activity-aware construction and hardware acceleration specifically designed for energy-harvesting scenarios.

\subsection{Related Systems and Their Limitations}

Several recent systems have attempted to address aspects of inference on energy-harvesting devices, but each has limitations our work addresses. SONIC~\cite{ResiRCA} enables DNN inference on individual EH nodes using specialized non-volatile accelerators but does not address distributed inference or coordination challenges. Camaroptera~\cite{chinchilla} provides software support for incremental DNN execution across power failures but focuses on single-node operation without considering distributed scenarios. InceptionZero~\cite{IntBeyondEdge} optimizes DNN architectures for intermittent execution but does not address communication efficiency or multi-node coordination. Cocktail~\cite{batteryfree} explores distributed inference but assumes reliable power for the aggregator node and does not handle incomplete inferences at worker nodes.

Our work builds upon these foundations while addressing their limitations through integrated design of scheduling, ensemble learning, and communication protocols specifically optimized for intermittent distributed systems.

%==============================================================================
\section{System Architecture and Problem Formulation}
\label{sec:ch2-system-architecture}

This section presents the system architecture for intelligent inference on intermittent systems and formally defines the optimization problem we address.

\subsection{System Overview}

We consider an energy-harvesting wireless sensor network (EH-WSN) consisting of multiple sensor nodes and a coordinating host device. This architecture is motivated by real-world deployments in body area networks, industrial monitoring, and environmental sensing where distributed sensors collaborate to perform complex inference tasks.

Each sensor node $i \in \{1, ..., N\}$ consists of a sensing unit that captures data streams (e.g., accelerometer, gyroscope etc.), an energy harvester that converts ambient energy to electrical power, an energy buffer (super-capacitor) with capacity $E_{\text{cap}}$, a non-volatile processor capable of preserving state across power failures, a DNN inference engine optimized for the specific sensor modality, and a communication interface for low-power wireless transmission. Each sensor node operates autonomously, making local decisions about whether to perform inference, transmit data, or conserve energy based on current conditions.

The host device, typically a smartphone or gateway, coordinates the distributed inference process. Unlike sensor nodes, we assume the host has reliable power (battery or mains) and greater computational resources. The host performs three key functions: result aggregation by combining predictions from multiple sensors, fallback inference by completing inference when sensors cannot, and adaptation by updating ensemble weights based on observed accuracy. Communication between nodes and host uses low-power wireless protocols (e.g., Bluetooth Low Energy, Zigbee). Communication is asymmetric: sensor-to-host transmission is energy-constrained while host-to-sensor communication is essentially free from the sensor's perspective.

\subsection{Energy Harvesting Model}
\label{sec:ch2-problem-formulation}

The energy dynamics at each sensor node are governed by the balance between harvested power and consumption:

\begin{equation}
\frac{dE_i(t)}{dt} = P_{\text{harvest},i}(t) - P_{\text{consume},i}(t) - P_{\text{leak},i}
\end{equation}

where $E_i(t)$ is stored energy, $P_{\text{harvest},i}(t)$ is the time-varying harvested power, $P_{\text{consume},i}(t)$ is power consumption, and $P_{\text{leak},i}$ represents capacitor leakage.

The harvested power depends on environmental conditions and harvester type. For solar harvesters, $P_{\text{solar}} = \eta \cdot A \cdot I(t)$ where $\eta$ is efficiency, $A$ is area, and $I(t)$ is irradiance. For kinetic harvesters, $P_{\text{kinetic}} = \alpha \cdot f(t) \cdot a(t)^2$ where $f(t)$ is movement frequency and $a(t)$ is acceleration. RF harvesters follow $P_{\text{RF}} = \beta \cdot P_{\text{transmitted}} / d^2$ based on path loss models. The stochastic nature of these sources means nodes experience intermittent operation when $E_i(t) < E_{\text{threshold}}$, where $E_{\text{threshold}}$ is the minimum energy for useful computation.

\subsection{Inference Task Model}

We consider classification tasks where the goal is to assign input data $\mathbf{x}_t$ to one of $C$ classes at each time step $t$. Each sensor node $i$ observes a local view $\mathbf{x}_t^{(i)}$ of the phenomenon and can execute a local DNN model $f_i: \mathcal{X}^{(i)} \rightarrow [0,1]^C$ that outputs class probabilities.

The energy cost of inference at node $i$ is:
\begin{equation}
E_{\text{inference},i} = \sum_{l=1}^{L} \left( \text{MACs}_l \cdot E_{\text{MAC}} + \text{Mem}_l \cdot E_{\text{mem}} \right)
\end{equation}

where $L$ is the number of layers, and $E_{\text{MAC}}$ and $E_{\text{mem}}$ are per-operation energy costs.

For communication, the energy cost depends on data volume:
\begin{equation}
E_{\text{comm}} = P_{\text{tx}} \cdot \frac{D}{R} + E_{\text{overhead}}
\end{equation}

where $P_{\text{tx}}$ is transmission power, $D$ is data size, $R$ is data rate, and $E_{\text{overhead}}$ accounts for protocol overhead.

\subsection{Problem Formulation}

Given the system model, we formulate the distributed inference problem as follows:

\textbf{Objective:} Maximize classification accuracy over time:
\begin{equation}
\max \sum_{t=1}^{T} \mathbb{1}[\hat{y}_t = y_t]
\end{equation}

where $\hat{y}_t$ is the ensemble prediction and $y_t$ is the true label.

\textbf{Subject to constraints:}

Energy feasibility requires that for each node $i$ and time $t$, actions can only be taken if sufficient energy is available:
\begin{equation}
\text{Action}_i(t) \in \mathcal{A}_i \text{ only if } E_i(t) \geq E_{\text{required}}(\text{Action}_i)
\end{equation}

Latency bounds require that classifications must complete within deadline $\tau$:
\begin{equation}
t_{\text{inference}} + t_{\text{comm}} + t_{\text{aggregation}} \leq \tau
\end{equation}

The system must handle intermittent operation where nodes may fail at any time when $E_i(t) = 0$.

The action space $\mathcal{A}_i$ for each node includes skipping inference (no energy consumption), performing full DNN inference locally, performing quantized DNN inference, constructing and transmitting clustering-based coreset, constructing and transmitting sampling-based coreset, or reusing previous result (temporal recall).

\subsection{Design Challenges}

This problem formulation reveals several key challenges our system must address. The optimization requires predicting future energy availability, which is inherently uncertain. Our approach uses activity-aware scheduling that exploits temporal patterns in both energy harvesting and classification tasks. When energy is insufficient for ideal operation (all nodes performing inference), the system must degrade gracefully. We achieve this through adaptive ensemble learning that maintains accuracy even with partial participation. The choice between local inference and data transmission depends on relative energy costs and accuracy implications. Our solution dynamically selects the most efficient option based on current conditions. Human activities and many sensing phenomena exhibit temporal continuity that can be exploited to reduce computation. Our temporal recall mechanism leverages this property while carefully managing the staleness-accuracy tradeoff.

The following sections detail how Origin and Seeker address these challenges through innovative algorithms and system design.

%==============================================================================
\section{Origin: Ensemble Learning for Intermittent Inference}
\label{sec:ch2-origin}

This section presents Origin, our first contribution that enables coordinated inference across multiple intermittent nodes through intelligent scheduling and adaptive ensemble learning.

\subsection{Motivation and Key Insights}

Our initial experiments with naive approaches reveal the fundamental challenge of distributed inference on intermittent systems. When three energy-harvesting sensors attempt to perform inference simultaneously, only 1\% of attempts succeed with all sensors completing, 9\% achieve at least one sensor completing, and 90\% fail entirely due to insufficient energy. These dismal completion rates arise because naive scheduling ignores two critical properties of intermittent systems.

\begin{figure}[t]
\centering
\begin{subfigure}[b]{0.48\textwidth}
  \includegraphics[width=\textwidth]{Chapter-2/Origin-DATE21-CameraReady/Figures/RR0Bar.pdf}
  \caption{Naive simultaneous scheduling}
  \label{fig:ch2-rr0-bar}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.48\textwidth}
  \includegraphics[width=\textwidth]{Chapter-2/Origin-DATE21-CameraReady/Figures/RR3Bar.pdf}
  \caption{Basic round-robin scheduling}
  \label{fig:ch2-rr3-bar}
\end{subfigure}
\caption{Inference completion rates under different scheduling strategies. Basic round-robin (b) significantly outperforms naive simultaneous scheduling (a) by ensuring only one sensor attempts inference at a time.}
\label{fig:ch2-scheduling-comparison}
\end{figure}

The first key insight is that energy accumulation requires time---sensors need periods of inactivity to harvest sufficient energy for inference. Continuous attempts at inference prevent energy accumulation, leading to repeated failures. The second insight is that not all sensors are equally important. Different sensors have varying accuracy for different activities. As shown in Figure~\ref{fig:ch2-individual-accuracy}, a wrist sensor excels at detecting writing or eating, while an ankle sensor better identifies walking or running. Origin leverages these insights through two key mechanisms: extended round-robin scheduling that provides energy accumulation time, and activity-aware scheduling that prioritizes the most capable sensor for each activity.

\begin{figure}[t]
\centering
\includegraphics[width=0.7\textwidth]{Chapter-2/Origin-DATE21-CameraReady/Figures/IndividualAccuracy.pdf}
\caption{Individual sensor accuracy for different activities in HAR. Each sensor excels at different activities based on its position and the movement patterns involved.}
\label{fig:ch2-individual-accuracy}
\end{figure}

\subsection{Extended Round-Robin Scheduling}

Basic round-robin scheduling, where sensors take turns performing inference, improves completion rates to 28\% by ensuring only one sensor attempts inference at a time, as shown in Figure~\ref{fig:ch2-scheduling-comparison}. However, this still leaves significant room for improvement.

\begin{figure}[t]
\centering
\includegraphics[width=0.8\textwidth]{Chapter-2/Origin-DATE21-CameraReady/Figures/ExtendedRR.pdf}
\caption{Extended round-robin scheduling policies. Basic round-robin (RR3) rotates through sensors immediately, while extended versions (RR6, RR9, RR12) insert no-op cycles for energy accumulation.}
\label{fig:ch2-extended-rr}
\end{figure}

Extended round-robin (ER-r) scheduling, illustrated in Figure~\ref{fig:ch2-extended-rr}, introduces deliberate idle periods between inference attempts:

\begin{equation}
\text{Schedule}(t) = \begin{cases}
\text{Sensor}_{(t \bmod r) / k} & \text{if } (t \bmod r) < N \\
\text{No-op} & \text{otherwise}
\end{cases}
\end{equation}

where $r$ is the round length, $N$ is the number of sensors, and $k = r/N$ determines the number of no-op cycles.

The key benefit is energy accumulation:
\begin{equation}
E_{\text{accumulated}} = \int_{t}^{t+k\tau} P_{\text{harvest}}(s) ds - k \cdot P_{\text{idle}} \cdot \tau
\end{equation}

Completion rates improve with longer rounds, reaching 52\% for RR12. However, longer rounds also increase latency and may miss transient activities.

\subsection{Activity-Aware Scheduling}

While ER-r improves completion rates, it treats all sensors equally despite their varying capabilities. Activity-aware scheduling (AAS) exploits these differences by predicting the next activity and scheduling the most capable sensor. The algorithm leverages temporal continuity in human activities---if a person is walking, they are likely to continue walking for multiple time steps. This allows us to anticipate the next activity with high probability and schedule accordingly.

\begin{algorithm}[t]
\caption{Activity-Aware Scheduling Algorithm}
\label{alg:activity-aware}
\begin{algorithmic}[1]
\State \textbf{Input:} Current activity $a_t$, sensor accuracies $\mathbf{A} \in \mathbb{R}^{N \times C}$, energy levels $\mathbf{E}$
\State \textbf{Output:} Next scheduled sensor $s_{t+1}$

\State $a_{\text{predicted}} \leftarrow a_t$ \Comment{Exploit temporal continuity}
\State $\text{rankings} \leftarrow \text{argsort}(\mathbf{A}[:, a_{\text{predicted}}])$ \Comment{Rank sensors by accuracy}

\For{$i$ in rankings}
    \If{$E_i \geq E_{\text{threshold}}$}
        \State \textbf{return} $i$ \Comment{Schedule highest-accuracy sensor with sufficient energy}
    \EndIf
\EndFor

\State \textbf{return} $\arg\max_i E_i$ \Comment{Fallback: sensor with most energy}
\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:activity-aware} shows our activity-aware scheduling approach. To minimize overhead, we store sensor rankings rather than raw accuracies, requiring only $\lceil \log_2 N \rceil$ bits per entry versus 32 bits for floating-point accuracy values.

\begin{figure}[t]
\centering
\includegraphics[width=0.8\textwidth]{Chapter-2/Origin-DATE21-CameraReady/Figures/CASAccuracy.pdf}
\caption{Classification accuracy comparison showing the improvement from activity-aware scheduling over basic round-robin approaches.}
\label{fig:ch2-cas-accuracy}
\end{figure}

Figure~\ref{fig:ch2-cas-accuracy} demonstrates the effectiveness of activity-aware scheduling, showing significant accuracy improvements over basic round-robin approaches across different activities.

\subsection{Adaptive Confidence Matrix}

Even with intelligent scheduling, not all sensors can participate in every ensemble decision due to energy constraints. Traditional majority voting fails when participation is incomplete and imbalanced. Origin addresses this through an adaptive confidence matrix that weights each sensor's contribution based on its historical performance.

The confidence matrix $\mathbf{C} \in \mathbb{R}^{N \times C \times C}$ captures each sensor's confusion patterns:
\begin{equation}
C_{i,j,k} = P(\text{true class} = k | \text{sensor } i \text{ predicts } j)
\end{equation}

Given predictions from available sensors $\mathcal{S}_t \subseteq \{1,...,N\}$, the ensemble prediction is:
\begin{equation}
\hat{y}_t = \arg\max_k \sum_{i \in \mathcal{S}_t} C_{i,p_i,k}
\end{equation}

where $p_i$ is sensor $i$'s prediction.

The confidence matrix adapts online using exponential moving average:
\begin{equation}
C_{i,j,k}^{(t+1)} = \alpha \cdot \mathbb{1}[y_t = k] + (1-\alpha) \cdot C_{i,j,k}^{(t)}
\end{equation}

This adaptation allows the system to personalize to individual users and adjust to changing conditions.

\subsection{Temporal Recall Mechanism}

Human activities exhibit strong temporal continuity---walking continues for many steps, sitting persists for minutes. Origin exploits this through temporal recall, reusing recent predictions when sensors lack energy for new inference:

\begin{equation}
\hat{y}_i(t) = \begin{cases}
f_i(\mathbf{x}_t^{(i)}) & \text{if } E_i(t) \geq E_{\text{inference}} \\
\hat{y}_i(t-\Delta_i) & \text{if } t - t_{\text{last},i} \leq \tau_{\text{recall}} \\
\varnothing & \text{otherwise}
\end{cases}
\end{equation}

where $t_{\text{last},i}$ is the last successful inference time and $\tau_{\text{recall}}$ is the maximum recall window.

The recall window is activity-dependent, reflecting different temporal scales. Static activities like sitting or standing use 5-second windows, cyclic activities like walking or running use 2-second windows, and transient activities like sit-to-stand transitions use 1-second windows. This mechanism dramatically reduces the number of required inferences while maintaining accuracy through intelligent reuse of recent results.

\subsection{Integrated Origin System}

The Origin system integrates all components described above into a cohesive workflow. The execution flow proceeds through schedule selection where AAS determines which sensor should attempt inference based on predicted activity and energy levels, energy checking to evaluate whether sufficient energy exists, inference or recall based on energy availability, ensemble aggregation at the host combining available predictions using confidence weighting, adaptation of the confidence matrix based on ground truth when available, and activity prediction using the ensemble result to inform the next scheduling decision.

This integrated approach achieves 83.88\% accuracy on HAR tasks---2.7\% higher than battery-powered baselines despite intermittent operation. However, Origin still faces a critical limitation: 41\% of scheduled inferences fail to complete, providing no value to the system. The next section introduces Seeker, which addresses this limitation through intelligent compression.

%==============================================================================
\section{Seeker: Enhancing Communication Efficiency}
\label{sec:ch2-seeker}

While Origin successfully coordinates inference across intermittent nodes, it cannot extract value from incomplete inference attempts. When a sensor lacks sufficient energy to complete DNN inference, it simply drops the sample, losing potentially valuable information. This section presents Seeker, which provides efficient fallback mechanisms through coreset-based compression, enabling sensors to contribute even when full inference is impossible.

\subsection{The Communication Challenge}

Origin's evaluation reveals a critical inefficiency: 41\% of inference attempts fail due to insufficient energy, and these failures provide zero value to the system. The obvious solution---transmitting raw data when inference fails---is impractical due to communication's high energy cost. Raw data transmission requires 70.16 $\mu$J per sample compared to 29.23 $\mu$J for DNN inference and only 8.27 $\mu$J for transmitting inference results. Transmitting raw data costs 2.4$\times$ more energy than local inference, making it infeasible for energy-harvesting systems. Classical compression techniques (e.g., JPEG, gzip) either don't apply to low-dimensional sensor data or destroy features critical for classification.

We need a compression approach that preserves classification-relevant features, requires less energy than full inference, adapts to available energy budgets, and enables accurate reconstruction at the host. Seeker addresses this challenge through coresets---small, weighted subsets that provably preserve properties relevant to specific computational tasks.

\subsection{Coreset-Based Compression for Sensor Data}

For sensor data classification, we construct coresets that maintain the statistical properties necessary for accurate inference while achieving substantial compression. Standard coreset construction treats all data points equally, but sensor data exhibits strong activity-dependent patterns. Seeker introduces activity-aware construction that prioritizes points based on their relevance to the current activity context.

\begin{algorithm}[t]
\caption{Activity-Aware Coreset Construction}
\label{alg:coreset-construction}
\begin{algorithmic}[1]
\State \textbf{Input:} Data window $\mathbf{X} \in \mathbb{R}^{T \times d}$, predicted activity $a$, size $m$
\State \textbf{Output:} Coreset $S = \{(\mathbf{x}_i, w_i)\}_{i=1}^m$

\State $\boldsymbol{\mu}_a \leftarrow \text{ActivityPrototype}(a)$ \Comment{Load activity-specific prototype}
\State $\mathbf{d} \leftarrow \|\mathbf{X} - \boldsymbol{\mu}_a\|_2$ \Comment{Compute distances to prototype}

\If{$E_{\text{available}} \geq E_{\text{cluster}}$}
    \State $\mathbf{C} \leftarrow \text{KMeans}(\mathbf{X}, m)$ \Comment{Clustering-based construction}
    \For{$i = 1$ to $m$}
        \State $S_i \leftarrow (\mathbf{C}_i, |\{\mathbf{x} : \text{cluster}(\mathbf{x}) = i\}|)$
    \EndFor
\Else
    \State $\mathbf{p} \leftarrow \text{softmax}(\mathbf{d} / \tau)$ \Comment{Importance sampling}
    \State $\text{indices} \leftarrow \text{sample}(m, \mathbf{p})$
    \For{$i$ in indices}
        \State $S_i \leftarrow (\mathbf{X}_i, 1/\mathbf{p}_i)$ \Comment{Inverse probability weighting}
    \EndFor
\EndIf

\State \textbf{return} $S$
\end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:coreset-construction} shows our activity-aware coreset construction. The activity-specific prototypes $\boldsymbol{\mu}_a$ are learned offline from training data, capturing the typical pattern for each activity. Points far from the prototype are more informative and receive higher selection probability, capturing the distinctive features of the current activity.

\begin{figure}[t]
\centering
\includegraphics[width=0.8\textwidth]{Chapter-2/Seeker-ASPLOS26/figs/DPRecovery.pdf}
\caption{Recoverable coreset construction and reconstruction pipeline. The encoder selects representative points while the decoder reconstructs the full signal using learned activity patterns.}
\label{fig:ch2-recoverable-coreset}
\end{figure}

Standard coresets preserve statistical properties but may not enable accurate reconstruction of the original signal. Seeker introduces recoverable coresets that support high-fidelity reconstruction through learned generators, as illustrated in Figure~\ref{fig:ch2-recoverable-coreset}. The reconstruction process uses a conditional generator:

\begin{equation}
\hat{\mathbf{X}} = G_\theta(S, a) = \text{Decoder}_\theta(\text{Embed}(S), \text{Embed}(a))
\end{equation}

where $G_\theta$ is trained to minimize reconstruction error:
\begin{equation}
\mathcal{L}_{\text{recon}} = \mathbb{E}_{\mathbf{X}, a}\left[\|\mathbf{X} - G_\theta(\text{Coreset}(\mathbf{X}, a), a)\|_2^2\right]
\end{equation}

This approach achieves 8.9$\times$ compression while maintaining less than 2\% accuracy degradation.

\subsection{Hierarchical Decision Framework}

Seeker implements a hierarchical decision framework that adaptively selects the most appropriate action based on available energy and data characteristics. The decision process progressively evaluates options from low to high energy cost, selecting the best feasible action.

\begin{figure}[t]
\centering
\includegraphics[width=0.7\textwidth]{Chapter-2/Seeker-ASPLOS26/figs/SeekerDecisionFlow.pdf}
\caption{Seeker's hierarchical decision flow. The system progressively evaluates options from low to high energy cost, selecting the best feasible action.}
\label{fig:ch2-seeker-decision}
\end{figure}

As shown in Figure~\ref{fig:ch2-seeker-decision}, the decision process follows several steps. First, it computes correlation with stored activity templates. If correlation exceeds a threshold, it reuses the previous result at minimal energy cost (0.54 $\mu$J). Next, it checks energy availability for DNN inference, offering full precision (29.23 $\mu$J) for highest accuracy or quantized 12-bit (16.58 $\mu$J) for moderate accuracy/energy tradeoff. If inference is infeasible, it constructs coresets using either clustering-based methods (17.04 $\mu$J) for higher quality but more energy, or sampling-based methods (16.84 $\mu$J) for lower quality but less energy.

This framework ensures sensors always contribute maximally within their energy constraints.

\subsection{Hardware Acceleration for Coreset Construction}

Coreset construction, particularly clustering-based methods, can be computationally expensive. Seeker introduces specialized hardware acceleration to make coreset construction energy-efficient.

The dominant operation in coreset construction is distance computation. We implement a parallel distance unit using ReRAM crossbars that perform analog matrix-vector multiplication in a single cycle, achieving 10$\times$ energy reduction compared to digital implementation. Clustering requires iterative updates that must survive power failures. Our non-volatile accumulator maintains cluster centers across power cycles using magnetic tunnel junctions (MTJs) for non-volatile storage with sub-nanosecond write times.

To further reduce energy, we implement quantized arithmetic with 8-bit distance computation (0.8$\times$ energy), 12-bit accumulation (0.6$\times$ energy), and 16-bit final output to maintain accuracy. Together, these hardware optimizations reduce coreset construction energy by 5.2$\times$, making it feasible within tight energy budgets.

\subsection{Integration with Origin}

Seeker seamlessly integrates with Origin's ensemble learning framework. Origin's activity-aware scheduler informs Seeker's coreset construction about the predicted activity. Reconstructed inferences receive lower confidence weights than direct sensor inferences, reflecting their approximate nature. Coreset construction considers temporal patterns identified by Origin to select the most representative samples. Decision thresholds adapt based on Origin's observed accuracy, becoming more aggressive when accuracy is high and more conservative when struggling.

This integration creates a complete system where Origin handles coordination and Seeker ensures efficient communication, together achieving 87.05\% accuracy on MHEALTH---5.89\% more accurate than battery-operated energy-optimized systems.

%==============================================================================
\section{Comprehensive Evaluation}
\label{sec:ch2-evaluation}

This section presents our evaluation of the integrated Origin-Seeker system across multiple dimensions: accuracy, energy efficiency, communication reduction, and robustness to different harvesting conditions.

\subsection{Experimental Setup}

We evaluate our system using a custom energy-harvesting sensor platform with ARM Cortex-M4F processor with non-volatile FRAM, 256KB FRAM and 64KB SRAM memory, 9-axis IMU sensors (accelerometer, gyroscope, magnetometer), solar (Powerfilm SP3-37) and kinetic (MIDE V21BL) energy harvesting, 100$\mu$F supercapacitor for energy storage, BLE 5.0 communication (Nordic nRF52840), and a custom ReRAM-based crossbar accelerator (simulated). The host device is a Samsung Galaxy S21 smartphone running Android 11.

We evaluate on two primary applications. For human activity recognition, we use the MHEALTH dataset (10 subjects, 12 activities, 3 sensor positions) and PAMAP2 dataset (9 subjects, 18 activities, 3 sensor positions) with 50 Hz sampling rate and 2.56-second windows (128 samples). For predictive maintenance, we use the NASA Bearing dataset with vibration data from industrial bearings, classifying normal operation and three fault types (inner race, outer race, ball) with 20 kHz sampling and 0.1-second windows.

We use optimized CNN architectures with 3 convolutional and 2 fully connected layers, 823K parameters (full) or 206K (pruned), supporting 32-bit (baseline), 16-bit, and 12-bit quantization, requiring 72M MACs (full) or 18M (pruned) per inference. Models are trained using TensorFlow and deployed using TensorFlow Lite Micro.

We compare against several state-of-the-art approaches: Cloud-Only (all data transmitted to cloud), Edge-Only (local inference with checkpointing~\cite{chinchilla}), Pruned-DNN (energy-optimized DNN~\cite{netadapt} on battery power), SONIC (single-node intermittent inference~\cite{ResiRCA}), Origin (our ensemble learning system without Seeker), and Origin+Seeker (complete integrated system).

\subsection{Classification Accuracy Results}

\begin{figure}[t]
\centering
\includegraphics[width=0.8\textwidth]{Chapter-2/Origin-DATE21-CameraReady/Figures/MHEALTHResults.pdf}
\caption{Classification accuracy on MHEALTH dataset across different approaches and energy harvesting scenarios.}
\label{fig:ch2-mhealth-results}
\end{figure}

Figure~\ref{fig:ch2-mhealth-results} shows classification accuracy on the MHEALTH dataset. The overall accuracy improves with increasing round-robin delay time due to the increasing number of completed inferences. Origin with RR-12 provides the best fit for HAR. For the MHEALTH dataset, RR12-Origin is 2.72\% more accurate than Baseline-2 (energy-aware pruned DNN). For certain activities like running, Origin exceeds even the unpruned Baseline-1 accuracy due to its use of a confidence matrix for weighted voting. Seeker further improves accuracy to 87.05\%---only 0.18\% less than a full-precision DNN on full power. Compared to battery-operated energy-optimized systems, Seeker is 5.89\% more accurate on MHEALTH.

\subsection{Energy Efficiency Analysis}

\begin{table}[t]
\centering
\caption{Energy consumption breakdown for different system configurations}
\label{tab:ch2-energy-breakdown}
\resizebox{\linewidth}{!}{%
\begin{tabular}{lcccc}
\toprule
\textbf{Configuration} & \textbf{Sensing} & \textbf{Compute} & \textbf{Comm.} & \textbf{Total ($\mu$J)} \\
\midrule
Cloud-Only & 2.3 & 0 & 70.2 & 72.5 \\
Edge-Only & 2.3 & 29.2 & 8.3 & 39.8 \\
Origin (RR3) & 2.3 & 9.7 & 2.8 & 14.8 \\
Origin (RR6) & 2.3 & 4.9 & 1.4 & 8.6 \\
Origin+Seeker & 2.3 & 3.2 & 2.1 & 7.6 \\
\bottomrule
\end{tabular}%
}
\end{table}

Table~\ref{tab:ch2-energy-breakdown} shows energy consumption breakdown. Seeker reduces communication energy by 8.9$\times$ compared to raw data transmission through coreset compression. Activity-aware scheduling reduces average computation by 3$\times$ by avoiding redundant inferences during continuous activities. The complete system achieves 9.5$\times$ energy reduction compared to cloud-only approaches while maintaining comparable accuracy.

\subsection{Communication Volume Reduction}

\begin{figure}[t]
\centering
\includegraphics[width=0.8\textwidth]{Chapter-2/Seeker-ASPLOS26/figs/SeekerFull.pdf}
\caption{Communication volume reduction through coreset compression across different activities and compression ratios.}
\label{fig:ch2-communication-reduction}
\end{figure}

Figure~\ref{fig:ch2-communication-reduction} quantifies communication savings. Coresets achieve 8.9$\times$ average compression, with activity-dependent variation: simple activities like standing achieve 12$\times$ compression, complex activities like running achieve 6$\times$ compression, and transitions achieve 4$\times$ compression. Varying coreset size from 5\% to 20\% of original data shows that 5\% size yields 82\% accuracy with 20$\times$ compression, 10\% yields 85\% accuracy with 10$\times$ compression, and 20\% yields 86.5\% accuracy with 5$\times$ compression. The system adaptively selects coreset size based on available energy.

\subsection{Robustness to Energy Harvesting Conditions}

\begin{figure}[t]
\centering
\includegraphics[width=0.9\textwidth]{Chapter-2/Seeker-ASPLOS26/figs/AnytimeCoreset.pdf}
\caption{System performance under different energy harvesting conditions, showing robustness to power availability variations.}
\label{fig:ch2-harvesting-robustness}
\end{figure}

Figure~\ref{fig:ch2-harvesting-robustness} evaluates robustness to harvesting variations across multiple energy harvesting sources. Our experiments with piezo-electric and RF energy sources demonstrate the versatility of Seeker, which outperforms prior HAR classifiers designed for EH across multiple harvested energy sources. The figure shows the comparison of scheduled inferences completed while using Seeker and prior state-of-the-art systems, demonstrating how Seeker leverages all proposed design components (including memoization, DNN inference, and coreset) to complete maximum compute at the edge while offloading minimum to the host device.

\subsection{Inference Completion Analysis}

Our experiments quantify the progression in inference completion rates. With na\"ive scheduling where three EH sensors work together to finish incoming inferences, only 1\% of cases have all sensors finish inference, while 9\% of the time at least one finishes. 90\% of the time, inference could not start due to lack of energy. With round-robin scheduling where one sensor performs inference while others accumulate energy, 28\% of inferences complete, while 72\% fail as sensors cannot harvest enough energy during idle periods. By offloading unfinished compute as coresets, Seeker finishes 58.67\% of inferences at the edge itself, reducing dropped inferences from approximately 40\% to approximately 6\% on average (5\% best case, 8\% worst case).

\subsection{Predictive Maintenance Case Study}

To demonstrate generalizability beyond HAR, we evaluate on industrial bearing fault detection using the Case Western Bearing Fault dataset. Seeker delivers an average accuracy of 84.73\%, which is only 0.66\% less than a fully powered system. The communication overhead is reduced by approximately 7$\times$ while finishing $\ge$80\% of scheduled compute using WiFi energy sources. For a typical grinding job taking about 8.2 seconds, the 5\% improvement over prior state-of-the-art impacts approximately 46k parts per year per machine (working 8 hours/day). In large-scale industries, both saving communication overhead while maximizing accuracy directly impact production economics.

\subsection{Theoretical Analysis and Performance Bounds}

Beyond empirical evaluation, we provide theoretical analysis of Origin-Seeker's performance bounds. For the ensemble learning component, we prove that with $N$ sensors each having individual accuracy $p_i > 0.5$ and making independent errors, the ensemble accuracy $p_{\text{ensemble}}$ satisfies:

\begin{equation}
p_{\text{ensemble}} \geq 1 - \exp\left(-2N\left(\bar{p} - 0.5\right)^2\right)
\end{equation}

where $\bar{p} = \frac{1}{N}\sum_{i=1}^{N} p_i$ is the average individual accuracy. This bound shows exponential improvement with the number of sensors, justifying our ensemble approach.

For coreset compression, we prove that our activity-aware construction achieves $(1+\epsilon)$-approximation for classification with coreset size:

\begin{equation}
|S| = O\left(\frac{d}{\epsilon^2} \log \frac{1}{\delta}\right)
\end{equation}

where $d$ is the data dimension and $\delta$ is the failure probability. This provides worst-case guarantees on compression-accuracy tradeoffs.

The temporal recall mechanism's effectiveness depends on activity autocorrelation. For activities with autocorrelation function $R(\tau)$, the expected accuracy degradation when using $\tau$-old predictions is:

\begin{equation}
\Delta_{\text{accuracy}}(\tau) \leq 2(1 - R(\tau))
\end{equation}

This bound guides our activity-specific recall window selection.

%==============================================================================
\section{Conclusion}
\label{sec:ch2-conclusion}

This chapter has presented a comprehensive approach to enabling intelligent inference on intermittent systems through the synergistic design of Origin and Seeker. By addressing both the coordination challenges of distributed intermittent nodes and the communication efficiency required for practical deployment, we have demonstrated that sophisticated machine learning tasks are feasible even under severe energy constraints.

\subsection{Key Contributions and Insights}

Our work makes several important contributions to intermittent computing. Origin's activity-aware scheduling and adaptive ensemble learning show that careful algorithm design can overcome the fundamental unreliability of intermittent nodes. The key insight is that not all sensors are equally important at all times---by predicting which sensor will be most valuable and scheduling accordingly, we can achieve high accuracy even when most nodes are unavailable.

Seeker demonstrates that when ideal operation (local inference) is impossible, systems can still extract value through intelligent fallback mechanisms. Coreset-based compression provides a principled way to preserve essential information while dramatically reducing communication costs, enabling contribution even from severely energy-constrained nodes.

The integration of specialized hardware accelerators for both DNN inference and coreset construction shows that intermittent systems require rethinking the entire stack. Our non-volatile processing units and quantized operations make previously infeasible computations practical within microwatt power budgets. While we focus on human activity recognition as a driving application, our evaluation on predictive maintenance demonstrates that these techniques generalize to other domains. Any application requiring distributed sensing and classification can benefit from our approach.

\subsection{Limitations and Future Directions}

Despite our contributions, several limitations remain that suggest directions for future research. Our current approach assumes models are trained offline on reliable infrastructure and deployed to intermittent devices. However, this creates a train-test mismatch---models trained on complete data may not be optimal for deployment scenarios where samples are frequently dropped. This observation motivates the next chapter's focus on training models specifically for intermittent deployment.

We assume direct communication between sensors and host. Extending to multi-hop scenarios where intermediate nodes may also be intermittent presents additional challenges in routing and reliability. Currently, each sensor runs a fixed model. Dynamically selecting model complexity based on available energy could further improve efficiency. Coreset compression potentially leaks information about the underlying data distribution. Developing privacy-preserving coresets for sensitive applications remains an open challenge.

\subsection{Bridging to Intermittency-Aware Training}

Having established how to perform inference on intermittent systems, we now turn to an equally critical question: How should models be trained when they will be deployed under intermittent conditions? The techniques presented in this chapter---ensemble learning, temporal recall, and coreset compression---all operate on pre-trained models that were developed assuming reliable execution. However, this train-test mismatch potentially leaves significant performance on the table.

Models trained with awareness of intermittent deployment could learn features robust to missing samples, optimize for partial execution under energy constraints, develop representations amenable to coreset compression, and adapt to the specific failure patterns of target deployment scenarios. The next chapter addresses this challenge by introducing training methodologies that explicitly account for intermittent execution. By closing the loop between training and deployment, we can develop models that not only survive intermittent operation but are fundamentally designed to thrive in it. This represents the next frontier in making intermittent systems truly practical for sophisticated machine learning applications.

Through Origin and Seeker, we have shown that intelligent inference is possible on intermittent systems. The question now becomes: Can we do even better by training models specifically for this challenging environment?