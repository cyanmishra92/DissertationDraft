% Dissertation Abstract

The proliferation of edge computing and Internet of Things (IoT) devices has created an unprecedented demand for intelligent systems that can operate without reliable power infrastructure. From tiny sensors harvesting microwatts of ambient energy to edge servers powered by kilowatts of solar generation, modern computing systems increasingly face intermittent power availability that fundamentally challenges traditional assumptions about computation. This dissertation presents a comprehensive framework for enabling machine learning in power-constrained computing systems, demonstrating that intermittency---rather than being a limitation to overcome---can be embraced through careful co-design across algorithms, architectures, and systems.

The work begins by addressing distributed inference in energy-harvesting wireless sensor networks, where individual nodes possess insufficient energy for complete neural network execution. Through the Origin and Seeker frameworks, we demonstrate how ensemble learning and coreset-based compression can enable collaborative inference across networks of intermittently powered devices, achieving 91.3\% accuracy on human activity recognition while operating entirely on harvested energy. This establishes the foundation for intelligent computation under severe power constraints.

Building upon these inference capabilities, we tackle the fundamental challenge of training neural networks under intermittent power. The NExUME framework introduces dynamic dropout and quantization techniques that adapt model complexity to match available energy, coupled with hardware-aware training that anticipates power failures. Through innovative checkpoint strategies and gradient accumulation methods, NExUME enables continuous learning on devices experiencing power interruptions every 50-200 milliseconds, achieving 93.7\% accuracy on CIFAR-10 while reducing energy consumption by 62\% compared to traditional approaches.

At the hardware level, we explore how analog computation can push the boundaries of energy efficiency. The LREyE system combines Schottky diode-based analog activation functions with ReRAM crossbar architectures to eliminate the primary energy bottleneck in neural accelerators: analog-to-digital conversions. Through hardware-aware training that embraces rather than fights analog non-idealities, LREyE achieves 68\% energy reduction compared to digital baselines while maintaining accuracy within 1-2\% of floating-point implementations. This demonstrates that co-designing algorithms and circuits can yield order-of-magnitude efficiency improvements.

The dissertation culminates by scaling these principles to edge servers powered by renewable energy. U\d{s}\'{a}s presents a morphable systolic array architecture that dynamically adjusts computational capacity to match solar power availability, enabling continuous learning on video streams without grid dependence. By operating across a 12$\times$ power range from 23W to 285W, U\d{s}\'{a}s achieves 93.1\% accuracy on urban traffic monitoring---4.96\% higher than grid-powered alternatives---while eliminating 2,234 kg of CO$_2$ emissions annually per server.

Across six orders of magnitude in power scale, from microwatt sensors to kilowatt servers, this dissertation identifies universal principles for intermittent computing: adaptive computation that scales with available energy, state preservation mechanisms appropriate to each scale, and quality maintenance techniques that ensure correctness despite interruptions. The work demonstrates that sustainable machine learning requires holistic thinking that spans devices, circuits, architectures, and algorithms.

The frameworks, architectures, and algorithms developed in this dissertation enable a future where intelligence can be embedded throughout our environment without increasing energy demands. By showing that intermittent operation can achieve superior results compared to constant-power alternatives, this work challenges the assumption that advancing AI capabilities requires ever-increasing energy consumption. As we face the dual challenges of ubiquitous intelligence and environmental sustainability, the techniques presented here provide a path toward computing systems that are both capable and responsible.