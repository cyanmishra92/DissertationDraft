Innovations in low-power computing, artificial intelligence, and communication technologies have led to the generation of intelligently connected devices that constitute the Internet of Things (IoT).  Wireless sensor networks (WSNs), one of the prominent classes of IoT deployments, is currently dominating and expected to be pervasive impacting many application spaces~\cite{Cisco-report} including, but not limited to, body area network~\cite{Origin,batteryfree}, industrial monitoring~\cite{industry4}, predictive maintenance~\cite{industry40}, commercial satellites\cite{oribitalEH1} and smart farming~\cite{smartfarmEH1}. Moreover, these WSNs are and will continue to participate in the production of rapid inferences to support increasingly complex tasks enabled by machine learning (ML) algorithms~\cite{netadapt,Origin}, often tweaked toward edge deployments, and applications of such edge analytics are also exploding with user and market demands. This represents a particularly challenging tension between energy availability and desired functionality, because the form factor constraints of the WSNs fundamentally limit active power, energy reserves, as well as compute and communication capabilities. 

For many WSNs, their participation in inference tasks has traditionally been limited to data collection and transmission, sometimes with modest preprocessing. Although several studies have shown the benefits of performing more inference closer to the data collection point~\cite{ResiRCA, intelligenceBeyondEdge,NVPMa, kang2017neurosurgeon, infocommDNNpart} and have applied these techniques to more powerful edge devices, their form factor-imposed limited energy storage, low-power operation points, and deployment scenarios have been a major impediment in executing compute-intensive inference tasks directly on such platforms. In contrast, communicating the data, often after little preprocessing, although popular, is not cheap in terms of power requirement, and often poses a challenge for remotely deployed and ultra-low-power WSNs. Previous works, trying to tackle this conflict between computation, communication, power requirements, and quality of service (QoS), have pursued three major approaches: inference effort partition optimization~\cite{kang2017neurosurgeon,batteryfree,infocommDNNpart,talhaDNN}, mitigation of energy provisioning limitations~\cite{IntBeyondEdge, chinchilla,NVPMa,ResiRCA,Origin}, and minimizing communication overheads~\cite{compression-kimura2005survey,quantcompression,compression-marcelloni2008simple,Ting-He-ArXiv, Ting-He-IEEE}. 

One of the emerging lines of work is to solve the energy provisioning problem at the edge by integrating energy harvesting (EH) to the sensor nodes while making them more capable performing complex compute intermittently, which has given rise to energy harvesting wireless sensor networks (EH-WSNs). Specifically, recent work~\cite{IntBeyondEdge, chinchilla} proposed EH, along with compiler/runtime optimizations and leveraging nonvolatile processors (NVP)~\cite{NVPMa,ResiRCA}, to increase local compute at the edge. EH as a solution has been particularly interesting as a means of addressing the sustainability issue of battery backing trillions of future devices. More importantly, EH can help us build sustainable distributed sensing/monitoring infrastructure at virtually inaccessible places such as oil wells, mines, and even satellite orbits~\cite{orbitaledge,EHuse}. However, harvested energy is fickle in nature, and typically harvested sources only deliver scant microwatts of power (see Figure~\ref{Fig:EHsota} for an overview). The sporadic nature of harvested energy and the lossy nature of EH-based storage and charging circuits call for using the harvested energy directly to perform intermittent compute rather than storing energy for some distant future use. On this front, recent works~\cite{Origin,LuciaCheckpoint,chinchilla} have specifically optimized DNN inference execution at the EH-edge nodes by utilizing adaptive dynamic check pointing, intelligent scheduling, and ensemble learning. Given the limitations of the EH budget, such approaches typically end up dropping many samples and not inferring from them locally. Importantly, they are often incapable of transmitting the raw data due to a lack of sufficient energy; for sensing tasks with modest inference requirements, performing inference and transmitting the result can take \textit{\textbf{less}} energy than transmitting raw data. However, to unleash remote deployment and sustainable, yet ubiquitous computing capabilities of WSNs, the development of efficient \textit{energy harvesting WSNs} (EH-WSNs), both for sensing and edge analytics, plays an essential role.

These wireless sensing devices (EH or otherwise) have long relied on compression techniques to mitigate data communication overheads~\cite{compression-kimura2005survey,quantcompression,compression-marcelloni2008simple}. However, when applied to low-dimensional sensor data,  classical lossy compression techniques tend to discard or distort some important features, which significantly degrades the inference accuracy. To mitigate the shortcomings of classical compression techniques, recent works~\cite{bachem2015coresets, Ting-He-ArXiv, Ting-He-IEEE} propose using \textit{coresets}, a data representation technique from computational geometry that preserves important, representative features when building a compressed form of the data, thus reducing the payload size while preserving data integrity for efficient edge communication. Although, with the help of coresets, one can efficiently offload minimal input representations to a more compute-capable device, performing accurate inference on coresets is non-trivial due to their low-dimensional nature. 

From the aforementioned challenges, it is evident that we need a concoction of both hardware-driven and software optimized solutions to build next-generation EH-WSNs with the ability to perform fine-grained intermittent computing while ensuring efficient network communication. Toward this, we propose \emph{Seeker}, a novel approach that leverages and extends coresets to efficiently execute DNN inference across a set of EH sensor nodes and a host mobile device. \textit{Seeker} focuses on building an efficient EH-WSN which can collaboratively work to maximize the inferences performed at the EH edge nodes.  Furthermore, it then applies innovative coreset techniques to efficiently and intelligently offload unfinished compute tasks to a more capable host to further increase the inferences that can be performed.
Particularly, \textit{Seeker} augments its coreset formation with \textit{application-awareness} to form an energy-aware, dynamically configured, and feature-preserving payload with minimal communication footprint. \textit{Seeker} provides hardware acceleration support for coreset formation to make them computationally efficient, adaptive, and accuracy-preserving specifically for EH-WSNs. The following are the \textbf{primary contributions} of our work:

\squishlist
\item \textbf{Efficient Communication:~}We enable low data volume communication by developing extensions to traditional coresets that enhances their applicability to EH-WSN inference scenarios. Specifically, we introduce an \emph{activity-aware coreset construction} technique to dynamically adapt to both activity and the available harvested energy, while conserving the maximum features of the data. This reduces the size of the communication payload by $8.9\times$. We also propose a \emph{recoverable coreset construction} technique which helps reconstruct the original data from compressed form with a minimum (as low as $0.02\%$) accuracy loss. 
\item \textbf{Efficient Computation:~} We augment a state-of-the-art EH-sensor node with quantized DNNs to increase the number of accurate inferences at the edge (by up to $40\%$). We leverage data memoization to skip unnecessary compute, saving inference execution time and energy.
\item \textbf{Efficient Hardware:~} We propose simple, low-power, and low-latency hardware to efficiently build coresets, further increasing the number of samples that can be inferred or transmitted under the EH budget, and thus significantly improving accuracy over the state-of-the-art ($\approx5\%$). We develop a non-volatile hardware accelerator, with multiple quantization support, for efficient DNN inference. 

\item \textbf{Adaptability:~}Although \textit{Seeker} is meant for EH-WSNs, the representation of data based on the coreset can easily be used on any commercial device for efficient communication.  

\item \textbf{Detailed Evaluation:~}We provide a detailed evaluation of our system and the proposed hardware design. Our evaluations show that, even when powered by an unreliable EH source, {\em Seeker}'s coreset-based optimizations result in better accuracy than that of a fully powered system running a state-of-the-art classifier optimized for energy efficiency. Specifically, \emph{Seeker} reaches  86.8\% top-1 accuracy in comparison to the 81.2\% accuracy of the baseline system. 
\squishend

