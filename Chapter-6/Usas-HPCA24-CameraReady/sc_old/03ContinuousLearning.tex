The first step to any data-driven learning algorithm is data collection and annotation. Since $\USS$ is a continuous learning framework and learns from the live data that the camera(s) capture, data collection is simply storing the live video feed. However, data annotation or labeling is more challenging. Classically, once data is collected, it is classified, labeled, and bounded by borders (bounding box) mostly using manual labor (at times with software assistance) or crowd sourcing~\cite{label01,label02,label03}. This requires the data to be present at a central location for manual inspection, both of which are not possible because of communication and privacy constraints. Therefore, we adapt a ``student-teacher paradigm''~\cite{student_teacher01}, where a more general, robust and larger model (typically with hundreds of millions of parameters~\cite{kerasAPI,cocoBM}) helps in annotating the data. However, because of the heavy compute requirements, the teacher model runs with a much slower frame rate and annotates only some (important) frames.
\begin{figure}[ht]
  \centering 
\includegraphics[width=0.8\linewidth]{figs/AutoLabel.pdf}
  \vspace{-12pt}\caption{Auto-labeling in $\USS$: Select frames only with low confidence as they might contain potentially new information, and use ensemble learning to improve the labeling.}
  \label{Fig:CLlabel}
  \vspace{-12pt}
\end{figure}
\subsection{Data Annotation}
\label{subsec:annotation}
\noindent \underline{\textbf{Picking the Important Ones:}} Typically, edge models are capable of inferring at the frame rate of the camera (at times, 30fps to 60fps)~\cite{coralT}. However, the teacher model used to label the incoming data cannot run at those high frame rates within a resource-constrained environment, like edge servers, where performing training is going to be even more resource consuming. Therefore, we employ an intelligent ``data sampling mechanism'' to select the frames that might contain new information and a potential candidate for learning. Figure~\ref{Fig:CLlabel} shows the different components of the student-teacher data annotation model adapted in $\USS$, where the edge model is the ``student'' (continuously retrained), and larger models are the ``teachers'' (the ones teaching the student about what-is-what). For each sampled frame, the classification results and the confidence matrix (output of the last layer) are  sent for annotation. If the student (or the edge model) is confident about the classification (e.g. a clear frame with no new objects, or a frame similar to one of the training samples), then that frame is discarded as it potentially contains little to no new information. However, if the student is not confident on the classification, the frame is then saved as a potential exemplar (we will further refine this in \S\ref{subsec:exemplar}). The potential exemplars are then further refined and classified by the teacher models. To improve the confidence of the teacher models, we employ an ensemble learning based weighted majority voting policy~\cite{cocktail}. Each of the teacher models infers on the exemplar frame and a majority vote decides the ground truth. This maximizes the accuracy of the teacher, and consequently minimizes the chance of the student model learning wrong labels. Note that the limited parameters of the student model makes it more sensitive to data fidelity and hence ensuring an accurate data labeling is very important for the end to end classification accuracy. We describe the impact of wrong labeling in our evaluation in \S\ref{sec:eval}.  
\begin{figure}[ht]
  \centering 
\includegraphics[trim={0 2cm 0 1pt},clip, width=\linewidth]{figs/biastrain.pdf}
  \vspace{-20pt}\caption{Distribution of different classes on a typical traffic pattern and the impact of training on the sampling bias.}
  \label{Fig:biastrain}\vspace{-8pt}
\end{figure}

\noindent \underline{\textbf{The Problem:}} However, this exemplar section mechanism has an inherent flaw. Consider a traffic camera looking at a busy street with a traffic signal. Due to the traffic distribution (e.g., more cars than buses), the camera typically sees a varied distribution of different classes, which might reflect in the exemplar set. Moreover, some of the static objects (like traffic light, stop sign etc.) might always be present in all the exemplars. This creates a sampling ``bias''~\cite{samplingbias} while performing the training, and often leads to catastrophic forgetting. Figure~\ref{Fig:biastrain} shows a typical traffic distribution (picked from Urban Traffic data~\cite{UrbanTraffic}) and the impact of sampling bias on class distribution. Note that, as some of the classes (e.g., bicycles) are barely present in the exemplar, the model tend to lose accuracy (because of catastrophic forgetting) on them, whereas the model rapidly over-fits for the classes with more examples (e.g., traffic light). 

\subsection{Proper Exemplar Selection}
\label{subsec:exemplar}
To tackle the sampling bias~\cite{samplingbias}, we adapt a representation learning~\cite{icarl} framework for designing the proper exemplar selection. The fundamental issue with the previous approach is the inability to select correct numbers of IID data for training. In addition to that, just DNN training cannot  learn new classes if there is no way to annotate and label new classes. Representation learning solves both these issues.  

\begin{figure}[h]
  \centering 
\includegraphics[width=0.9\linewidth]{figs/iCARLD.pdf}
  \vspace{-6pt}\caption{Representation learning flow and cartoon example of updating the feature space upon encountering new data.}
  \label{Fig:iCARLD}
  \vspace{-6pt}
\end{figure} 

Figure~\ref{Fig:iCARLD} shows the decision flow with a toy example that illustrates  how the representation learning for the incremental learner and classifier works in $\USS$. The learner (here the teacher classes) need to properly classify the data, learn if the data is a new type of one of the older classes, and identify if it encounters a new class. We achieve this by clustering the feature vector of the Large DNN model. Fundamentally, we use the larger DNN models as feature extractors which take the data and converts them into a feature vector. In the original training phase, these feature vectors are separated using a clustering algorithm like K-means~\cite{icarl}. The cluster centers for each data ($\mu_y$ for class $y$) are calculated as $\mu_y = \frac{1}{P_y}\sum_{p \in P_y}\Phi(p)$,
% \begin{align*}
% \mu_y = \frac{1}{P_y}\sum_{p \in P_y}\Phi(p), 
% \end{align*},
where $P_y$ is the number of samples belonging to class (or cluster $y$), and $\Phi$ is the feature extraction function working on the data $p$. These clusters fundamentally represent the classes in the high dimensional feature space. When the classifier sees new data ($x$), it extracts the features, and calculates its distance from all the cluster centers as $y^* = \min_{y = 1 \dots t}||\Phi(x)-\mu_y||$. There are three cases:

\noindent\textbf{Case-1:} If the data is close to one of the cluster centers and belongs to its cluster boundary, then it falls into the bucket of that particular class. This typically happens if the data are very similar to the training samples. 

\noindent\textbf{Case-2:} If the data belongs to a known class, but is significantly different from the training samples (like the triangle in Figure~\ref{Fig:iCARLD}), it falls not too far from one of the clusters. This distance of the new data from the cluster center is called the ``distillation loss''~\cite{icarl}. An encounter of a new example of the existing class is followed by an update to the cluttering by minimizing the classification loss of the newly-seen data.

\noindent\textbf{Case-3:}  Finally, if the classifier sees an example of a new class (like the circle in Figure~\ref{Fig:iCARLD}, not learnt before), then the feature vector of the data sits far from all the cluster centers indicating an unknown class. The distance of this feature vector from the other cluster center is called ``classification loss''~\cite{icarl}, and this triggers a new round of clustering with an updated number of clusters.

Over multiple time windows, the representation learner goes through all the possible exemplars selected by using the confidence matrix (discussed in \S\ref{subsec:annotation}) and creates an exemplar set with same number of examples from each possible classes.  Since we have multiple teacher models, each of them contributes to the exemplar set, making it robust and removing bias. To efficiently implement the exemplar selection algorithm,  $\USS$ implements the major portions using a ``custom hardware'' (discussed in \S\ref{subsec:RLHW}). The annotations on the new exemplar set created by the representation learner is compared against the confidence matrix of the edge model to calculate the ``drift''. Consequently, this exemplar set becomes the training data for the continuous learning, which consequently minimizes the drift. Once the student model is trained with the exemplar set, the data is discarded and the feature space for the teacher models is updated. By doing this,  $\USS$ keeps {\em both} the student model and the teacher models ``updated'' all the time. Since the feature space of the teacher model is updated using the K-means algorithm, the major computation is the training of the student model using the exemplar data. Although efficient hardware accelerators~\cite{dadiannao,sparsetrain,sarmaSparse} have been developed to do the same, these accelerators are typically designed with a ``throughput-first'' approach and are neither configured nor capable of operating with an intermittent power source. Deploying sufficient battery resources to allow intermittency-unaware designs to operate on solar power is neither efficient nor sustainable.% The only way these hardware accelerators can operate with dynamic solar power is by storing the harvested power to a battery and then utilizing the same to perform training, which is neither efficient nor sustainable. 

%%%%%

