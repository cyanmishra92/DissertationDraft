The rampant growth, and anticipated sustained expansion of data collection and consumption are currently driving data-driven analytics using trained inference models, with significant economic impact. Amidst the myriad of data-driven domains, urban mobility, smart cities, autonomous driving, and the Internet of Things (IoT) emerge as some of the most rapidly expanding fields contributing to the global economy, amounting to more than 4 trillion US~dollars~\cite{ADMarket, SCMarket, UMMarket, IoTMarket}. These statistics underscore the profound significance and transformative potential of these data-driven realms, delineating their pivotal role in shaping the landscape of computing technology, from algorithms to architecture.

What distinguishes these data is their diverse origin, spanning from IoT devices to wearables, and their acquisition from challenging environments, including autonomous driving and urban mobility scenarios. Consequently, they frequently exhibit a phenomenon known as ``data drift'', where the incoming data deviates from the distribution of the originally trained model, leading to degradation in inference accuracy.

\noindent\underline{\textbf{Mitigating Data Drift:}} Dealing with data drift in edge compute nodes presents a significant challenge. While larger models with more parameters may exhibit limited data drift due to their increased capacity to generalize, deploying such large models on edge compute nodes can be difficult due to inherent limitations in form factor, energy efficiency, thermal constraints, and compute resources. To accommodate these constraints, it is a common practice to employ compressed Deep Neural Network (DNN) models, that are quantized, distilled, or otherwise reduced in size. However, while compressed models are essential for meeting resource limitations, they are more sensitive to data drift because they may not generalize as effectively.

Traditionally, data drift has been handled by cloud-based periodic re-training using continuous learning algorithms~\cite{continuelearn01, icarl}. However, there are challenges in resources, privacy, and sustainability to utilize existing techniques at envisioned scales. As these applications become more ubiquitous, particularly in urban deployments for tasks like traffic surveillance, autonomous driving, and health analytics~\cite{UM1, UM2, UM3}, demands on communication bandwidth and network reliability limit the direct streaming of diverse data (e.g., video, 3D point cloud, sensor, voice) from numerous sensor-compute nodes to the cloud. Moreover, recent changes in privacy regulations across multiple countries~\cite{sweden-data, azure-data} call for preserving the privacy of citizens~\cite{ekya} and may preclude streaming personal data to third-party cloud services. As a result, ``on-premise'' \textit{edge servers}~\cite{aws-outposts, azure-ase} have become prime choices for local inference and prediction~\cite{ieee-computer, edgevideo-1, getmobile, edgevideo-2}, necessitating the handling of both learning and inference tasks to meet application needs, including privacy preservation, reduced data communication, and disaggregated computing. Finally, although recent studies have suggested co-locating training and inference~\cite{ekya} to tackle privacy concerns without significantly affecting the inference service, the power demand associated with equipping multiple commercial edge servers~\cite{aws-outposts, azure-ase} for both tasks hinders sustainable scaling. 

\noindent\underline{\textbf{The Problem Space:}} To address the multi-faceted challenges of sustainable, scalable and privacy-preserving continuous learning at edge servers, several crucial problem spaces must be explored. Firstly, the issue of \textbf{(non-)supervision} arises, demanding the ability to label data without human intervention to preserve privacy during the learning process. While recent works~\cite{student_teacher01, ekya} have attempted to tackle this concern through student-teacher paradigms, efficiently deploying such approaches in complex data modalities (e.g., multi-class video, 3D point cloud) remains a formidable challenge. Ensuring adherence to Service Level Agreements (SLAs), where inference typically utilizes a lower-resource model~\cite{mobilenetv2, tinyyolo} and labeling is performed using a larger teacher model~\cite{incremental01, incremental02, incremental03} at a much lower rate, necessitates informed decisions regarding deployment placement and sampling rates.

Secondly, the issue of \textbf{functionality} comes to the fore, requiring effective continuous learning from often non-Independently and Identically Distributed (non-IID) data. Such non-IID data distributions, evident in tasks like standard traffic monitoring with varied class observations (e.g., more cars than buses, all frames having $\texttt{STOP}$ signs), may introduce \textit{sampling bias}\cite{samplingbias, icarl} in the network. This challenge can be addressed through proper \textit{exemplar selection} algorithms employing representation learning techniques\cite{exemplar01, icarl}, capable of learning new classes in real-time. However, these compute-intensive algorithms can be optimized further through dedicated hardware acceleration.

Thirdly, the aspect of \textbf{sustainability} poses a critical question of deploying such systems, ideally with minimal reliance on the power grid for learning tasks. Designing a learning platform that can adapt to intermittent renewable energy sources (e.g., solar power) and maintain a minimal operational carbon footprint~\cite{opExCarbon} is paramount. Such a platform should continuously make progress on unsupervised labeling, exemplar building, and continuous learning, and maximize \textit{drift mitigation} while minimizing power consumption. Moreover, the system must accommodate \textbf{support for intermittency} inherent in sustainable power sources like solar and wind. While incorporating conventional battery storage can mitigate intermittency, it introduces environmental and sustainability challenges associated with resource extraction, production, and replacement~\cite{batterysus1, batterysus2, batterysus3, batterysus4, batterysus5, batterysus6, batterysus7}. An ideal solution would entail a battery-free system ({\em not} energy storage-free, i.e., still with some capacitive storage), circumventing these concerns and aligning with the objectives of sustainable and reliable continuous learning at the edge.

To these ends, we propose \US{},
\footnote{Vedic goddess of dawn in Hinduism~\cite{ushas}; emphasizing the dawn of sustainable continuous learning and significance of solar power in our design.}
a HW-SW co-design approach to building sustainable, scalable, drift-mitigating edge analytics platforms using harvested power to support continuous learning. \US{}, unlike prior edge-focused analytics approaches (e.g., Ekya~\cite{ekya}), detaches the inference and training hardware, as the training task is the major source of the compute, power, and time consumption.  \US{} introduces an algorithmic framework for data labeling using a teacher-student model, designing the exemplar selection using representation learning and determining the right set of hyperparameters using micro profiling to energy-efficiently continuously train the DNNs with the selected exemplar sets.  \US{} also employs a dynamically morphable systolic array for enabling energy-efficient computing within the harvested power envelope.  {\bf Key contributions} of the work include:
\squishlist
\item We propose algorithmic enhancements of {\em continuous learning} for mitigating data drift and design a {\em student-teacher based automated data labelling algorithm}, to prepare training exemplars from input data. We use a two-level data annotation mechanism: exemplar identification based on the confidence matrix of the student model, followed by a representation learning based exemplar selection by ensembling multiple teacher models. Our policy updates {\em both} the teacher and student models for robust unsupervised learning. 

\item We implement a {\em micro-profiler}, which predicts the right set of hyper-parameters to efficiently perform the training tasks on an energy-harvesting edge server while operating within its power budget and minimizing data drift. 

\item We design a {\em morphable hardware accelerator} that efficiently maps training tasks, is suitable for intermittent computing, and can adapt its capabilities to reduce power emergencies without devolving to grid operation. We discuss how the proposed hardware techniques can be adapted by many of the current DNN training accelerators to add similar dynamism in sustainability-sensitive environments. 

\item Finally, we evaluate \US{} in depth on a {\em real-world traffic data set}~\cite{UrbanTraffic} and perform sensitivity studies on other classes (audio, IMU) of data. Our algorithmic framework for performing continuous learning has a 4.96\% greater mean accuracy than a na\"ive continuous learner. Power estimations of our hardware design, modeled by Design Compiler~\cite{SynDC}, indicate that the proposed morphable accelerator approach can save up to 234.95kWH/year/edge-server, compared to running continuous learning on a state of the art DNN accelerator and 2.63MWH/year/edge-server, compared to utilizing a datacenter-scale GPU for learning on the edge. 
%Our accelerator with the help of our software solutions can save up to 200lbs of $CO_2$ emission per year compared to the state-of-the-art DNN accelerator, and about 2230lbs of $CO_2$ compared to a data center scale GP-GPU.   
\squishend


















% The incessant growth and the anticipated sustained expansion of data collection and consumption are presently driving data-driven analytics, revolutionizing the economic market. 
% %Among the plethora of these data-driven fields, urban mobility, smart cities, autonomous driving, and the Internet of Things (IoT) stand out as some of the fastest-growing domains. 
% Amidst the myriad of data-driven domains, urban mobility, smart cities, autonomous driving, and the Internet of Things (IoT) emerge as some of the most rapidly expanding fields contributing to more than 4 Trillion Dollars~\cite{ADMarket, SCMarket, UMMarket,IoTMarket} to the global economy. 
% %As of the year 2030, these domains demonstrate a momentous trajectory, exemplified by the following projected figures: the consumer IoT market is forecasted to attain a staggering value of \$556 Billion with a compound annual growth rate (CAGR) of 12.7\%~\cite{IoTMarket}; smart cities are on course to achieve a remarkable \$1024.4 Billion with a CAGR of 14.9\%~\cite{SCMarket}; autonomous driving is poised to reach an unparalleled sum of \$2161.79 Billion, supported by an extraordinary CAGR of 40.1\%~\cite{ADMarket}; and urban mobility is expected to scale up significantly to \$660 Billion, steadily advancing at a CAGR of 10\%~\cite{UMMarket}. 
% % Move to motivation
% These compelling statistics underscore the profound significance and transformative potential of these data-driven realms, delineating their pivotal role in shaping the landscape of computing technology - from algorithms to architecture.
% %The uniqueness of these domains lies in the convergence of edge compute nodes, equipped with sensors such as cameras, LiDARs, IMUs, among others, which not only act as data producers but also serve as the very place where inference is performed~\cite{ekya, Origin, seekerArX}.
% What sets these data apart is their origin from a diverse array of users, spanning from IoT devices to wearables, and their acquisition from various environments, including autonomous driving and urban mobility scenarios. Furthermore, due to the user and environment-driven nature of the data, they frequently exhibit a phenomenon known as data drift, where the incoming data deviates from the distribution of the originally trained model.

% \noindent\underline{\textbf{Mitigating Data Drift:}} %Additionally, these data-driven domains might encounter scenarios where they are confronted with changes in the underlying relationships between input features and the target variable over time, which is referred to as concept drift.
% Indeed, larger models with higher parameters have demonstrated better capabilities in handling data drift due to their increased capacity to learn from diverse and evolving data. However, deploying such large models on edge compute nodes can be challenging due to their inherent limitations in terms of form factor, energy efficiency, thermal constraints, and computing resources.
% To accommodate the constraints of edge compute nodes, it is common practice to employ compressed models, such as quantized, distilled, or otherwise reduced in size. While compressed models are essential for meeting the resource limitations, they may not generalize as effectively as their larger counterparts, making them more susceptible to drift.

% Traditionally, data drift has been handled by cloud-based periodic (re)training using continuous learning algorithms~\cite{continuelearn01,icarl}. 
% However, as these applications are becoming ubiquitous, especially in urban deployments (for traffic surveillance, autonomous driving, health analytics~\cite{UM1, UM2, UM3}), demands on communication bandwidth and network reliability constrain the streaming of these data (video, 3D point cloud, sensor, voice etc.) from these numerous sensor-compute nodes directly to the cloud. 
% Moreover, recent changes in privacy regulations across multiple countries~\cite{sweden-data, azure-data} provide for protecting the privacy of their citizens~\cite{ekya} in a manner that can preclude streaming personal data to third-party cloud services. 
% As a result of these pressures and trends, on premise \textit{edge servers}~\cite{aws-outposts,azure-ase} have become prime choices for local inference and prediction~\cite{ieee-computer,edgevideo-1,getmobile,edgevideo-2}. 
% Edge servers must now handle these learning tasks as well as inference tasks in order to meet all application needs: preserving privacy, minimizing data communication, and dis-aggregated computing.

% %Prior works have proposed compute co-location of training and inference~\cite{ekya} to handle the privacy issue with minimally impacting the inference service. the power demand~\cite{aws-outposts} of equipping an increasing number of commercial edge servers~\cite{aws-outposts, azure-ase} to run {\em both} training and inference impedes \textit{\textbf{sustainable}} scaling. For example, to enable continuous learning for traffic surveillance in the city of New York with $\approx 56k$ cameras~\cite{NYCcamera} with state-of-the-art edge servers~\cite{AWSOutpostPricing}, and co-location policies~\cite{ekya} might (\textit{conservatively}) consume 17MW of power, which could contribute a staggering 156 metric tons of $CO_2$ emission/day\footnote{Electricity production in United States accounts for 0.85lbs of $CO_2$ emission per kilo Watt-hour of energy production~\cite{CO2FootPrint}}. For such wide-scale deployments to be practical, the power budget for performing continuous learning needs to be lowered: \textbf{The carbon footprint of DNN training has become a major concern}~\cite{DNNenergy01,DNNcarbon01,DNNcarbon02,DNNcarbon03}\textbf{, and needs to be thought of as a design component/first-class metric.} Although green data centers~\cite{metaGreen, MSGreen} may greatly mitigate portions of this problem, they still do {\em not} address the issues with data-privacy and communication bandwidth in the current context. The similar problem prevails for other application spaces with different data modalities (LiDAR and Camera for autonomous driving; IMU, bio-sensors, and Speech for IoT etc.), yet we do not have a solution that addresses the privacy preserving, distributed continuous learning in a sustainable way. 

% Recent studies have suggested co-locating training and inference~\cite{ekya} to tackle privacy concerns without significantly affecting the inference service. 
% Nonetheless, the power demand associated with equipping multiple commercial edge servers~\cite{aws-outposts, azure-ase} for both tasks hinders sustainable scaling. 
% For example, deploying continuous learning for traffic surveillance in a city like New York, utilizing approximately 56k cameras~\cite{NYCcamera} and state-of-the-art edge servers~\cite{AWSOutpostPricing} with co-location policies~\cite{ekya}, may conservatively consume 17MW of power, leading to a staggering 156 metric tons of $CO_2$ emissions per day. 
% Reducing the power budget for continuous learning is essential, as the carbon footprint of DNN training has emerged as a prominent concern~\cite{DNNenergy01, DNNcarbon01, DNNcarbon02, DNNcarbon03}, demanding careful consideration as a primary design metric.
% Although green data centers~\cite{metaGreen, MSGreen} provide partial mitigation, they fail to address data privacy and communication bandwidth challenges in the current context. 
% Similarly, other applications with diverse data modalities, such as LiDAR and Camera for autonomous driving, IMU, bio-sensors, and Speech for IoT, face similar issues. 
% However, \textit{attaining a sustainable solution for privacy-preserving, distributed continuous learning remains an ongoing pursuit.}

% %\noindent\underline{\textbf{The Problem Space:}} To perform sustainable, scalable, and privacy-preserving continuous learning at edge servers offers challenges from multiple dimensions. First, \textbf{(non-)supervision}: Can the data collected be labeled without human-intervention (hence privacy preserving) to perform the learning process? Although recent works~\cite{student_teacher01,ekya} have tried to address this problem by using a student-teacher paradigm, how can we efficiently deploy this in the context of complex data modalities (multi class video, 3D Point Cloud)? To keep up with the Service level agreement (SLA), inference is typically performed using a model with a lower resource footprint~\cite{mobilenetv2,tinyyolo}, and the labeling is done using a larger teacher model~\cite{incremental01,incremental02,incremental03} but at a much lower rate. Deciding their deployment placement as well as the sampling rate is not a trivial problem. Second,  \textbf{functionality}: Can we perform effective continuous learning from the often non-IID (Independent and Identically Distributed) data actually observed? For example, in a standard traffic monitoring task, we might have a varied distribution of the observed classes, like more cars than buses, all frames having stop signs etc., which might induce \textit{sampling bias}~\cite{samplingbias,icarl} in the network. This can be solved by having a proper \textit{exemplar selection} algorithm using representation learning (e.g.,~\cite{exemplar01, icarl}) which can also learn new classes {\em on the fly}. Although exemplar selection can be done offline, these algorithms are compute-intensive~\cite{icarl}, and can benefit from having dedicated hardware acceleration. Third, \textbf{sustainability}: In order to scale with increasing deployments, can we sustainably deploy such a system with minimum (preferably no) reliability on the power grid for learning tasks, thereby operating on renewable energy sources(e.g., solar power) with minimal operational carbon footprint~\cite{opExCarbon}? This calls for architecting  a new learning platform, which can adapt to the intermittent nature of renewable, low-carbon power sources and continuously make forward-progress~\cite{NVPma} on the tasks at hand, namely, unsupervised labeling, exemplar building, and continuous learning. Moreover, it should be able to select the right set of hyper-parameters for training the models to maximize {\em drift mitigation} while minimizing the power consumption for doing so. And, finally, \textbf{support for intermittency}: Since a majority of the sustainable power sources, like solar, wind etc., are {\em intermittent} in nature, can we design the system to cater towards or even take advantage of the intermittency? While incorporating a small battery storage system could alleviate the degree of intermittency, it introduces a myriad of environmental and sustainability challenges associated with resource extraction, production, and replacement~\cite{batterysus1, batterysus2, batterysus3, batterysus4, batterysus5, batterysus6, batterysus7}. Hence, an ideal solution would be to implement a battery-free system, which would circumvent these concerns.

% \noindent\underline{\textbf{The Problem Space:}} To address the multi-faceted challenges of sustainable, scalable, and privacy-preserving continuous learning at edge servers, several crucial problem spaces must be explored. Firstly, the issue of \textbf{(non-)supervision} arises, demanding the ability to label data without human intervention to preserve privacy during the learning process. While recent works~\cite{student_teacher01, ekya} have attempted to tackle this concern through student-teacher paradigms, efficiently deploying such approaches in complex data modalities (e.g., multi-class video, 3D point cloud) remains a formidable challenge. Ensuring adherence to Service Level Agreements (SLAs), where inference typically utilizes a lower-resource model~\cite{mobilenetv2, tinyyolo} and labeling is performed using a larger teacher model~\cite{incremental01, incremental02, incremental03} at a much lower rate, necessitates informed decisions regarding deployment placement and sampling rates.

% Secondly, the issue of \textbf{functionality} comes to the fore, requiring effective continuous learning from often non-Independently and Identically Distributed (non-IID) data. Such non-IID data distributions, evident in tasks like standard traffic monitoring with varied class observations (e.g., more cars than buses, all frames having stop signs), may introduce \textit{sampling bias}\cite{samplingbias, icarl} in the network. This challenge can be addressed through proper \textit{exemplar selection} algorithms employing representation learning techniques\cite{exemplar01, icarl}, capable of learning new classes in real-time. However, these compute-intensive algorithms can be optimized further through dedicated hardware acceleration.

% Thirdly, the aspect of \textbf{sustainability} poses a critical question of deploying such systems sustainably, ideally with minimal reliance on the power grid for learning tasks. Designing a learning platform that can adapt to intermittent renewable energy sources (e.g., solar power) and maintain a minimal operational carbon footprint~\cite{opExCarbon} is paramount. Such a platform should continuously make progress on unsupervised labeling, exemplar building, and continuous learning, requiring appropriate hyper-parameter selection to maximize \textit{drift mitigation} while minimizing power consumption.

% Moreover, the system must accommodate \textbf{support for intermittency} inherent in sustainable power sources like solar and wind. While incorporating small battery storage can mitigate intermittency to some extent, it introduces environmental and sustainability challenges associated with resource extraction, production, and replacement~\cite{batterysus1, batterysus2, batterysus3, batterysus4, batterysus5, batterysus6, batterysus7}. An ideal solution would entail a battery-free system, circumventing these concerns and aligning with the objectives of sustainable and reliable continuous learning at the edge.