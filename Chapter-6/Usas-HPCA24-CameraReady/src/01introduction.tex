%%%%%

Video data analytics using Deep Neural Networks (DNNs) has been gaining significant traction (expected to reach about \$19.3~Billion by 2030~\cite{YahooVideo}), especially for video streaming workloads like urban mobility~\cite{googleUrbanMobility}, autonomous driving~\cite{ADVmotional, bellevuereport}, anomaly detection~\cite{anomalyD}, and sports analytics~\cite{deepSports2,deepSports1}. Classically, most applications that perform analytics on streaming video send the data from (multiple) camera(s) to the cloud, where the analytics tasks are actually performed. However, as cameras are becoming ubiquitous, especially in urban deployments for traffic surveillance~\cite{UM1, UM2, UM3}, demands on communication bandwidth and network reliability constrain the streaming of video data from these numerous cameras directly to the cloud. Moreover, recent changes in privacy regulations across multiple countries~\cite{sweden-data, azure-data} provide for protecting the privacy of their citizens~\cite{ekya} in a manner that can preclude streaming videos to third-party cloud services. As a result of these pressures and trends, on premise \textit{edge servers}~\cite{aws-outposts,azure-ase} have become prime choices for local inference and prediction~\cite{ieee-computer,edgevideo-1,getmobile,edgevideo-2}.  

\noindent\underline{\textbf{Edge Servers:}} While edge servers are a practical means to avoid relying on (expensive) high bandwidth, high-reliability connections to the cloud and can perform analytics locally (and therefore privately), they often feature more limited resources (e.g., weak GPUs, limited memory~\cite{AWSOutpostPricing}) than are available for cloud-based analytics tasks. Moreover, to keep up with the SLA (Service Level Agreement) demands of DNN-based learning tasks, 
%like pedestrian detection, vehicle number calculation, traffic orchestration~\cite{Intel-urbanmobility}
approximation and specialization techniques like model compression, model pruning, and platform-aware model design~\cite{compression01, compression02, compression03, netadapt} are often applied. These techniques reduce the latency and resource demands, but limit the generalizability of the compressed models used at the edge, which often leads to increased sensitivity to {\em data drift}~\cite{compressiondrift01,compressiondrift02} (i.e., compressed models suffer greater accuracy reduction than the originals when the observed distribution drifts with respect to the training distribution). Traditionally, data drift has been handled by cloud-based periodic (re)training using continuous learning algorithms~\cite{continuelearn01,icarl}; given the aforementioned constraints on offloading the data directly to the cloud, edge servers must now handle these learning tasks as well as inference tasks in order to meet all application needs: preserving privacy, minimizing data communication, and dis-aggregated computing. 

\noindent\underline{\textbf{Compute Co-location:}} However, even if efficiently managed~\cite{ekya}, the co-location of inference and training widens the disparity between edge server resource constraints and compute requirements: In deployments that were already making quality compromises to fit inference tasks on edge resources, additionally performing training imposes a substantial overhead. Furthermore, the power demand~\cite{aws-outposts} of equipping an increasing number of commercial edge servers~\cite{aws-outposts, azure-ase} to run {\em both} training and inference impedes \textit{\textbf{sustainable}} scaling. For example, to enable continuous learning for traffic surveillance in the city of New York with $\approx 56k$ cameras~\cite{NYCcamera} with state-of-the-art edge servers~\cite{AWSOutpostPricing}, and co-location policies~\cite{ekya} might (\textit{conservatively}) consume 17MW of power, which could contribute a staggering 156 metric tons of $CO_2$ emission/day\footnote{Electricity production in United States accounts for 0.85lbs of $CO_2$ emission per kilo Watt-hour of energy production~\cite{CO2FootPrint}}. For such wide-scale deployments to be practical, the power budget for performing continuous learning needs to be lowered: \textbf{The carbon footprint of DNN training has become a major concern}~\cite{DNNenergy01,DNNcarbon01,DNNcarbon02,DNNcarbon03}\textbf{, and needs to be thought of as a design component/first-class metric.} Although green data centers~\cite{metaGreen, MSGreen} may greatly mitigate portions of this problem, they still do {\em not} address the issues with data-privacy and communication bandwidth in the current context. 

%\noindent\underline{\textbf{Non-trivial Nature:}} 
Furthermore, designing a continuous learning solution for video analytics comes with challenges from the algorithm and architecture sides as well. The conventional approach, where (multiple) human agent(s) check the video data and label it for training the continuous learner, is not viable. This requires the video data (at times 1080p @30fps) to be streamed to one or multiple server-nodes and then manually inspected and labeled, defeating both the bandwidth and the privacy constraints that motivated an edge-based solution. Even with labeled data, constructing a unique exemplar set each time to train the model  continuously without sampling bias~\cite{samplingbias}, while also including new classes, is not trivial.  This clearly calls for looking into {\em continuous learning} on edge servers from a sustainability aspect, while preserving the core functionality, and providing novel hardware-software co-design to meet efficiency challenges. 

\noindent\underline{\textbf{The Problem Space:}} To perform sustainable, scalable, and privacy-preserving continuous learning from video data at edge servers offers challenges from multiple dimensions. First, \textbf{(non-)supervision}: Can the data collected be labeled without human-intervention (hence privacy preserving) to perform the learning process? Although recent works~\cite{student_teacher01,ekya} have tried to address this problem by using a student-teacher paradigm, how can we efficiently deploy this in the context of video data? To keep up with the SLA, inference is typically performed using a model with a lower resource footprint~\cite{mobilenetv2,tinyyolo}, and the labeling is done using a larger teacher model~\cite{incremental01,incremental02,incremental03} but at a much lower frame-rate. Deciding their deployment placement as well as the frame sampling is not a trivial problem. Second,  \textbf{functionality}: Can we perform effective continuous learning from the often non-IID (Independent and Identically Distributed) data actually observed? For example, in a standard traffic monitoring task, we might have a varied distribution of the observed classes, like more cars than buses, all frames having stop signs etc., which might induce \textit{sampling bias}~\cite{samplingbias,icarl} in the network. This can be solved by having a proper \textit{exemplar selection} algorithm using representation learning (e.g.,~\cite{exemplar01, icarl}) which can also learn new classes {\em on the fly}. Although exemplar selection can be done offline, these algorithms are compute-intensive~\cite{icarl}, and can benefit from having dedicated hardware acceleration. Third, \textbf{sustainability}: In order to scale with increasing deployments, can we sustainably deploy such a system with minimum (preferably no) reliability on the power grid for learning tasks, thereby operating on renewable energy sources(e.g., solar power) with minimal operational carbon footprint~\cite{opExCarbon}? This calls for architecting  a new learning platform, which can adapt to the intermittent nature of renewable, low-carbon power sources and continuously make forward-progress~\cite{NVPma} on the tasks at hand, namely, unsupervised labeling, exemplar building, and continuous learning. Moreover, it should be able to select the right set of hyper-parameters for training the models to maximize {\em drift mitigation} while minimizing the power consumption for doing so. And, finally, \textbf{support for intermittency}: Since a majority of the sustainable power sources, like solar, wind etc., are {\em intermittent} in nature, can we design the system to cater towards or even take advantage of the intermittency? 

% \vspace{2pt}\noindent\underline{\textbf{The Solution Space:}} To tackle the aforementioned problems, we propose $\USS$\footnote{Vedic goddess of dawn in Hinduism~\cite{ushas}; emphasizing the dawn of sustainable continuous learning and significance of solar power in our design.}, a sustainable intermittent computing framework for performing continuous learning on video analytics with the help of hardware software co-design and using only harvested (solar) power for all continuous learning tasks. The major components of $\USS$ are shown in Fig.~\ref{Fig:IntroFig}. $\USS$, unlike prior edge-focused video analytics approaches (e.g. Ekya~\cite{ekya}), detaches the inference(\circled{c}) and training hardware, as the training task is major source of the compute, power, and time consumption. Moreover, current commercial off-the-shelf edge devices, such as EdgeTPU~\cite{coralT}, can be used to perform complex inference tasks like single-shot object detection (SSD) using a lightweight model like MobileNetV2~\cite{mobilenetv2} as they can achieve a throughput of $\approx$71 frames/second with $\le 2W$ power budget. Therefore, our focus is on performing DNN training for continuous leaning on specialized edge servers capable of intermittent computing and designed to run on solar power only. The algorithmic framework of $\USS$ helps in data labeling using teacher student model, designing the exemplar selection using representation learning (\circled{a}) and determining the right set of hyperparameters using micro profiling (\circled{b}) to energy-efficiently train the DNNs with the selected exemplar set which is used to perform continuous learning. $\USS$ proposes a novel hardware platform centered around sustainability and intermittent computing. Both the algorithmic components and  DNN training are implemented using an efficient hardware capable of executing these computes with an intermittent power source. To perform the continuous learning (i.e., repeated DNN training) $\USS$ uses a {\em systolic array-based}  hardware (\circled{c}) that can morph (read ``dynamically reconfigure'') to fit into the instantaneous power budget of the harvested source, instead of relying on the inefficient~\cite{NVPma,resiRCA,Origin,IntBeyondEdge,chinchilla} (energy) store and execute paradigm for a fixed accelerator configuration. The major {\bf contributions} of the work include:

\noindent\underline{\textbf{The Solution Space:}} To tackle the aforementioned problems, we propose $\USS$\footnote{Vedic goddess of dawn in Hinduism~\cite{ushas}; emphasizing the dawn of sustainable continuous learning and significance of solar power in our design.}, a sustainable intermittent computing framework for performing continuous learning on video analytics with the help of hardware software co-design and using only harvested (solar) power for all continuous learning tasks.
%The major components of $\USS$ are shown in Fig.~\ref{Fig:IntroFig}. 
$\USS$, unlike prior edge-focused video analytics approaches (e.g. Ekya~\cite{ekya}), detaches the inference and training hardware, as the training task is major source of the compute, power, and time consumption. Moreover, current commercial off-the-shelf edge devices, such as EdgeTPU~\cite{coralT}, can be used to perform complex inference tasks like single-shot object detection (SSD) using a lightweight model like MobileNetV2~\cite{mobilenetv2} as they can achieve a throughput of $\approx$71 frames/second with $\le 2W$ power budget. Therefore, our focus is on performing DNN training for continuous leaning on specialized edge servers capable of intermittent computing and designed to run on solar power only. The algorithmic framework of $\USS$ helps in data labeling using teacher student model, designing the exemplar selection using representation learning and determining the right set of hyperparameters using micro profiling to energy-efficiently train the DNNs with the selected exemplar set which is used to perform continuous learning. $\USS$ proposes a novel hardware platform centered around sustainability and intermittent computing. Both the algorithmic components and  DNN training are implemented using an efficient hardware capable of executing these computes with an intermittent power source. To perform the continuous learning (i.e., repeated DNN training) $\USS$ uses a {\em systolic array-based}  hardware that can morph (read ``dynamically reconfigure'') to fit into the instantaneous power budget of the harvested source, instead of relying on the inefficient~\cite{NVPma,resiRCA,Origin,IntBeyondEdge,chinchilla} (energy) store and execute paradigm for a fixed accelerator configuration. The major {\bf contributions} of the work include:

% \begin{figure}[tb]
%   \centering\vspace{-0pt} 
% \includegraphics[width=\linewidth]{figs/IntroDesignNew.pdf}\vspace{-4pt}
%   \caption{The high-level design components of \textbf{\US{}}.}
%   \label{Fig:IntroFig}
%   \vspace{-18pt}
% \end{figure}

\squishlist
\item We propose a novel {\em continuous learning algorithm} for mitigating {\em data drift}, targeting video analytics at edge servers. Our primary focus is on designing a sustainable and privacy preserving platform that can perform learning tasks using locally harvested energy. 
\item We design a {\em student-teacher based automated data labelling algorithm} to prepare exemplar (training data) from input video. We use a two-level data annotation mechanism: exemplar identification based on the confidence matrix of the student model, followed by a representation learning based exemplar selection by ensembling multiple teacher models. Our policy updates {\em both} the teacher and student models for robust unsupervised learning. 
\item We implement a {\em micro-profiler}, which predicts the right set of hyper-parameters to efficiently perform the training tasks on the edge server while operating within the harvested power budget and minimizing the data drift. 
\item We design a {\em morphable hardware accelerator} to efficiently map the training tasks. The morphable hardware uses intermittent computing, and can adapt its compute capabilities to stay within the harvested power budget. This ensures forward progress even when there is not enough power, without devolving to grid operation. 
\item Finally, we evaluate \US{} on a {\em real-world traffic data set}~\cite{UrbanTraffic}. Our algorithmic framework for performing continuous learning has a 4.96\% greater mean accuracy than a na\"ive continuous learner. Power estimations of our hardware design, as modeled by Design Compiler~\cite{SynDC}, indicate that the morphable accelerator approach can save up to 234.95kWH/year/edge-server compared to running continuous learning on a state of the art DNN accelerator and 2.63MWH/year/edge-server compared to utilizing a data center scale GPU for learning on the edge. 
%Our accelerator with the help of our software solutions can save up to 200lbs of $CO_2$ emission per year compared to the state-of-the-art DNN accelerator, and about 2230lbs of $CO_2$ compared to a data center scale GP-GPU.   
\squishend

%%%%%

