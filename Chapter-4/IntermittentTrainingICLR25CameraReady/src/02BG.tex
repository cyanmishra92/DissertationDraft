%%%%%

\noindent \textbf{Energy Harvesting and Intermittent Computing:}  The exploding usage of IoTs, connected devices, and  wearable electronics project the number of battery operated devices to be 24.1 Billion by 2030~\cite{transformaiot}. This has a significant economic (users, products and data generating dollar value) as well as environmental (battery and e-waste) impact~\cite{usas}. In fact, advances in EH has lead to a staggering development in intermittently powered battery-free devices~\cite{chinchilla, intelligencebeyondedge, resirca, wisp, MIT}. A typical EH setup consists of 5 components, namely, energy capture (solar panel, thermocouple, etc), power conditioning, voltage regulation (buck or boost converter), energy storage (super capacitor) and compute unit (refer \S Appendix~\ref{appendix:EH} for details about each of them). To cater towards the sporadic power income and failures, an existing body of works explores algorithms, orchestration, compiler support, and hardware development~\cite{eap, netadapt,intermittentNAS, chinchilla, alpaca, resirca, islam2022enabling, usas, origin, nvpMA, incidental, ambient}. Most of these works  rely on software checkpointing (static and dynamic~\cite{chinchilla}, refer \S Appendix~\ref{appendix:ckpt}) to save and restore, while some of the prior works developed nonvolatile hardware~\cite{nvpMA, incidental} which inherently takes care of the checkpointing. Considering the scope of these initiatives, it is crucial to acknowledge that, despite the substantial support for energy harvesting and intermittency management, developing intermittency-aware applications and hardware necessitates multi-dimensional efforts that span from theoretical foundations to circuit design.

\noindent \textbf{Intermittent DNN Execution/Training:} As the applications deployed on such EH devices demand analytics, executing DNNs on EH devices and EH-WSNs have become prominent~\cite{DFI,intelligencebeyondedge, resirca,origin}. However, due to computational  constraints, limited memory capacity and restricted operating frequencies, many of these applications fail to complete inference execution with satisfactory SLOs, despite comprehensive software and hardware support~\cite{origin}. While the works relying on loop-decomposition or task partition (e.g., see ~\cite{resirca,intelligencebeyondedge} and the references therein) ensure  ``forward progress'', they do not  guarantee an inference completion while meeting SLOs. Optimizing DNNs for the energy constraints~\cite{netadapt, eap}, or performing early exit and depth-first slicing~\cite{DFI, Zygarde} does ensure more forward progress, but such approaches compromise accuracy while often imposing scheduling overheads  and higher memory footprint. One major issue is, most of the works leverage ``pre-existing'' DNNs, which are typically designed for running on a stable resource environment, while being deployed on an intermittent environment with pseudo notion of stability via check-pointing, and therefore, one direction of works~\cite{intermittentNAS} looks for performing  network architecture search for intermittent devices. However, this research direction only accounts for fixed lower and upper bounds of energy and compute capacities, overlooking the ``sporadic'' nature of energy availability and the elasticity of the compute hardware (i.e., the ability to dynamically scale frequency, compute, and memory). Moreover, while the DNN is designed to operate within a specific power window, it is \textit{not} trained to adapt to these fluctuations. Consequently, during extended periods of energy scarcity, the system lacks mechanisms for computational approximation, such as dynamic dropouts (neuron skipping) and dynamic quantization. \textit{Essentially, the DNN is trained to manage within a static resource budget, ignoring the ``dynamism'' of the resources}. In contrast, our work prioritizes the integration of this dynamism in both the network architecture search (NAS) and the training phases, adapting more effectively to fluctuating energy and compute conditions.

%%%%%


