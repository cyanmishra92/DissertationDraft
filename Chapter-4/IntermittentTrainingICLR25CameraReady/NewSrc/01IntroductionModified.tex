%%%%%
The increasing demand for ubiquitous, sustainable, and energy-efficient computing, combined with advancements in energy harvesting systems, has spurred significant research into battery-less devices~\cite{intelligencebeyondedge, mouse, origin, wisp, MIT}. Such platforms represent the future of the Internet of Things (IoT) and energy harvesting wireless sensor networks (EH-WSNs). Equipped with modern machine learning (ML) techniques, these devices can revolutionize computing, monitoring, and analytics in remote, risky, and critical environments such as oil wells, mines, deep forests, oceans, remote industries, and smart cities. However, the intermittent and limited energy income of these deployments demands optimizations for ML applications at the algorithm~\cite{eap, tianyi, intermittentNAS}, orchestration~\cite{chinchilla, origin}, compilation~\cite{alpaca}, and hardware development~\cite{resirca, islam2022enabling, usas} layers. Despite these advancements, achieving consistent and accurate inference—thereby meeting service level objectives (SLOs)—in such intermittent environments remains a significant challenge, exacerbated by unpredictable resources, form-factor limitations, and variable computational availability, particularly when employing task-optimized deep neural networks (DNNs).

There are two major problems with performing DNN inference under intermittent power. \textbf{(I) Energy Variability}: Even though DNNs can be tailored to match the average energy income of the energy harvesting (EH) source through pruning, quantization, distillation, or network architecture search (NAS)~\cite{netadapt, eap, intermittentNAS}, there is no guarantee that the energy income consistently meets or exceeds this average. When the income falls below the threshold, the system halts the inference and checkpoints the intermediate states (via software or persistent hardware)~\cite{chinchilla, resirca}, resuming upon energy recovery. Depending on the EH profile, this might lead to significant delays and SLO violations. \textbf{(II) Computational Approximation}: To address (I) and maintain continuous operation, EH-WSNs may skip some compute during energy shortfalls by dropping neurons (zero padding) or by approximating computations (quantization). Adding further approximation to save energy atop an already heavily reduced network can propagate errors through the layers, leading to significant accuracy drops~\cite{Zygarde, moreisless, DFI, kang}, further violating SLOs.

In certain energy-critical scenarios, even EH-WSNs applying state-of-the-art techniques fail to consistently meet SLOs, sometimes skipping entire inferences to deliver results on time. Fundamentally, while current DNNs can be trained or fine-tuned to fit within a given resource budget—be it compute, memory, or energy—they are \emph{not} trained to expect a variable or intermittent resource income. Although intermittency-aware NAS~\cite{intermittentNAS}, could alleviate certain problems, they often assume fixed resource constraints and do not account for real-time energy fluctuations. {Moreover, existing works like Keep in Balance~\cite{yen2023keep}, Stateful Neural Networks~\cite{yen2022stateful}, ePerceptive~\cite{patel2019eperceptive}, and Zygarde~\cite{Zygarde} address aspects of intermittent computing but do not integrate energy variability awareness directly into the training and inference processes to enable dynamic adaptation.} This calls for revisiting the entire training process; we need to train the DNN in such a way that it is aware of the intermittency and \emph{adapts} to it.

Motivated by these challenges, we propose \textbf{NExUME} (\textbf{N}eural \textbf{Ex}ecution \textbf{U}nder Inter\textbf{M}ittent \textbf{E}nvironments), a novel framework designed specifically for environments with intermittent power and EH-WSNs, with potential applications in any ultra-low-power inference system. {NExUME uniquely integrates energy variability awareness directly into both the training (\textbf{DynFit}) and inference (\textbf{DynInfer}) processes, enabling DNNs to dynamically adapt computations based on real-time energy availability.} This involves an innovative strategy of learning instantaneous energy-aware dynamic dropout and quantization selection during training, and an intermittency-aware task scheduler during inference. The method includes targeted fine-tuning that not only regularizes the model but also prevents overfitting, enhancing robustness to fluctuations in resource availability. \textbf{Our key contributions} can be summarized as follows:

\begin{itemize} [leftmargin=*]
\itemsep-0.2em
\item \textbf{DynFit}: A novel training optimizer that embeds energy variability awareness directly into the DNN training process. This optimizer allows for dynamic adjustments of dropout rates and quantization levels based on real-time energy availability, thus maintaining learning stability and improving model accuracy under power constraints.

\item \textbf{DynInfer}: An intermittency- and platform-aware task scheduler that optimizes computational tasks for intermittent power supply, ensuring consistent and reliable DNN operation. DynInfer leverages software-compiler-hardware co-design to manage and deploy tasks. With the help of DynFit, DynInfer provides $6\%$--$22\%$ accuracy improvements with $\leq 5\%$ additional compute over existing methods.

\item \textbf{Dataset}: A first-of-its-kind machine status monitoring dataset, involving multiple types of EH sensors mounted at various locations on a Bridgeport machine to monitor its activity status, facilitating research in predictive maintenance and Industry 4.0 applications.
\end{itemize}
%%%%%