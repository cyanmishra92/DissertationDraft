%%%%%

\begin{figure*}[]
 \centering
    \subfloat[Standard DNN inference architectures: (I) PIM based, (II-III) Micro controller based]{\includegraphics[width=\linewidth]{figs/MotivationArchitecture.pdf}\label{fig:BaseArch}}%
    
    \subfloat[Understanding the trends, and details of the current deployments: (I -- IV) Understanding the breakdown of area and power for edge DNN deployment; (V) Higher power efficiency due to PIM; (VI-VII) Impact of hardware aware training on accuracy.]{\includegraphics[width=\linewidth]{NewResultFigs/combined_analysis_complete_final.pdf}\label{fig:loss}}%
    %\vspace{-8pt}
    \caption{An understanding of the current state of the art: (a) Different available architectures for deploying edge intelligence; (b) Contribution of the different moving parts of the edge ecosystem towards inference accuracy, and resource utilization.
    }
    \label{fig:Motivation}
\end{figure*}

% -----------------------------------------------------------------------------
% Section 2 – Background & Motivation
% -----------------------------------------------------------------------------
The appetite for on‑device intelligence continues to grow unabated: cameras that catalog endangered wildlife, vibration nodes that forecast industrial faults, and environmental beacons that harvest microwatts from ambient light are all expected to execute deep learning workloads where cloud connectivity is either intermittent or undesirable.  In such scenarios, the energy available for computation is typically measured in microjoules per inference, and any joule spent ferrying data between memory and logic is a joule that cannot be spared~\cite{qiu2020resirca, song2020drq, gobieski2019intelligence, maeng2018adaptive, IMBNature}.  Figure~\ref{fig:Motivation} juxtaposes three hardware datapaths that currently compete for these edge deployments and exposes the architectural friction points that motivate our work.

\noindent \textbf{The Baseline MCU Route:}  A traditional micro‑controller unit~\cite{msp_exp430fr5994} (\textit{Figure~\ref{fig:Motivation}(a,II)}) executes each multiply–accumulate (MAC) in the digital domain.  Even when the core is augmented with a low‑energy accelerator (LEA)~\cite{msp_exp430fr5994, TILEA} for vector arithmetic, the device must still marshal every feature map through on‑chip SRAM, dispatch DMA transfers, and consult a 12‑bit successive‑approximation ADC for sensor input.  The pie charts in \textit{Figure~\ref{fig:Motivation}(b,II–III)} quantify the result: more than three‑fifths of the total power is squandered on memory and I/O traffic, while the arithmetic engine that designers labor to optimize consumes barely one‑third.

\noindent \textbf{What an Analog PIM Can Offer:}  At the opposite extreme, a ReRAM crossbar array~\cite{qiu2020resirca, singh2020nebula, reramNature} (\textit{Figure~\ref{fig:Motivation}(a,I)}) stores weights as conductance and performs an entire matrix–vector multiplication in a single Ohmic step.  In principle, this in-situ analog arithmetic delivers more than two orders of magnitude better computational efficiency than a digital MCU pipeline; \textit{Figure~\ref{fig:Motivation}(b,V)} hints at this gap, with the crossbar  going >{150}{GOps/watt}~\cite{singh2020nebula} while the MCU stall below {5}{GOps/watt}.  Unfortunately, the same analysis also reveals an inconvenient truth: once the currents leave the array, they must be digitized so that a micro‑controller can apply a non‑linear activation and orchestrate the next layer.  The data converters that perform this bookkeeping account for more than eighty percent of the ReRAM power budget (\textit{Figure~\ref{fig:Motivation}(b,I)}), and they monopolize almost one‑third of the silicon area (\textit{Figure~\ref{fig:Motivation}(b,IV)}).  Every layer therefore suffers a round‑trip through an ADC, through the MCU, and back through a DAC before the next vector is launched, thus obliterating much of the intrinsic advantage promised by analog PIM~\cite{singh2020nebula, shafiee2016isaac, chi2016prime}.

\noindent \textbf{Why Existing Remedies Fall Short:}  Designers have responded along two axes.  Digital accelerators seek to overlap DMA transfers with MAC execution or compress activations in transit, yet the memory wall shown in \textit{Figure~\ref{fig:Motivation}(b,III)} remains stubborn.  Fully analog image sensor pipelines such as \textit{RedEye} move small convolution kernels into the focal plane, but they trade flexibility for leakage‑prone capacitors and struggle to scale beyond a handful of layers.  State-of-the-art ReRAM platforms like ISAAC~\cite{shafiee2016isaac}, PRIME~\cite{chi2016prime}, Nebula~\cite{singh2020nebula}, and ResiRCA~\cite{qiu2020resirca} push the arithmetic efficiency envelope, but all ultimately capitulate to the same mixed‑signal boundary: after {\em every} crossbar operation, the partial sums are digitized so that a rectified‑linear‑unit (ReLU) can be executed in software.

\noindent \textbf{Analog Noise Aware Training:} Accuracy in analog ReRAM crossbars can degrade significantly due to device variability, IR drop, and circuit-level noise. Without proper compensation, accumulated analog errors can lead to substantial accuracy losses. For example, when deploying MicroNet~\cite{li2021micronet} on CIFAR-10~\cite{cifar} (Refer Figure~\ref{fig:loss}(VI-VII)) using a 128$\times$128 ReRAM crossbar, the ideal FP32 accuracy of approximately 94\% is maintained in higher precisions (e.g., FP16 yielding around 93\%), while naive quantization to 4-bit (INT4) results in only 90\% accuracy. By contrast, incorporating analog-aware training—which explicitly models IR drop, transistor and diode non-linearities, and other process variations via quantization-aware training~\cite{qat} (QAT)—enables the network to recover much of the lost performance, with the 4-bit model achieving 91.63\% top-1 accuracy. 

This hardware-aware training approach not only adapts the weights and activations to the limited signal range and noise of the analog domain but also utilizes a realistic analog noise model to simulate the effects of process variations during the forward pass. The technique effectively reduces the accuracy gap between ideal digital computation and real-world analog behavior. In a similar vein, the \emph{LeCA}~\cite{ma2023leca} framework adopts a task-specific co-design strategy where an in-sensor autoencoder is jointly trained with the downstream classifier. This enables the system to learn compressive features that are robust to aggressive analog quantization and noise. For instance, LeCA achieves only a 0.97\% accuracy loss at a 4$\times$ compression ratio on ImageNet, and a 2.01\% loss at 8$\times$ compression, demonstrating that integrating analog non-idealities into the training loop substantially mitigates the degradation typically associated with low-bit analog implementations. 

Together, these results highlight the necessity of analog-aware co-training to preserve DNN accuracy under real-world hardware noise conditions, thereby ensuring energy-efficient deployment on analog processing-in-memory systems.


\noindent \textbf{An Opportunity at the Analog–Digital Seam:}  The evidence in Figure~\ref{fig:Motivation} therefore suggests a different approach.  If the dominant non‑linearity ReLU could be realized directly in the ``current domain'', and if the inevitable analog non‑idealities (IR drop, device mismatch, thermal drift) could be accounted for during training, then two consecutive neural network layers could be {\em fused} inside the crossbar fabric before a single low‑precision conversion.  Hence, eliminating just one ADC/DAC cycle out of every two slashes both energy and latency, and it does so {\em without}  forfeiting the programmability that a digital top‑level controller affords.

The remainder of this paper explores how close we can come to that ideal.  We begin by revisiting the circuit primitives available in standard processes and show that a modest Schottky‑diode network can {\em approximate} ReLU with a forward drop of only {{0.15}{V}}.  We then embed a model of that circuit, along with spatial IR‑drop maps and device‑level variability, into the training loop so that the network learns to live with the hardware it will ultimately inhabit.  Finally, we build a 64‑tile prototype around the  ISAAC‑class~\cite{shafiee2016isaac} crossbars and demonstrate, on contemporary CNNs and compact transformers, the energy–latency gains that Figure~\ref{fig:Motivation} foreshadows.
%%%%%