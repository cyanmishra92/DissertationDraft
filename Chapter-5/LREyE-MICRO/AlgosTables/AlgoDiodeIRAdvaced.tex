\begin{algorithm}[h]
\caption{Revised Training Algorithm Incorporating Diode Activation and IR Drop Modeling}
\label{alg:revised_training}
\begin{algorithmic}[1]
\Require Training data $\{(x^{(i)}, y^{(i)})\}_{i=1}^{N}$, learning rate $\eta$, number of epochs $E$
\Ensure Trained weights $\{ w_{ij}^{(l)} \}$ and biases $\{ b_i^{(l)} \}$

\For{epoch $=1$ to $E$}
    \For{each mini-batch}
        \State Initialize gradients: $\Delta w_{ij}^{(l)} = 0$, $\Delta b_i^{(l)} = 0$
        \For{each training example $(x, y)$ in mini-batch}
            \State \textbf{Forward Propagation}:
            \State Set input activations: $a_j^{(0)} = x_j$
            \For{each layer $l$}
                \State Compute pre-activation: $z_i^{(l)} = \sum_{j=1}^{N_{l-1}} w_{ij}^{(l)} a_j^{(l-1)} + b_i^{(l)}$
                \State Sample diode parameters:
                \State \quad $V_{\text{th}}^{(l)} \sim \mathcal{N}(\mu_{V_{\text{th}}}, \sigma_{V_{\text{th}}}^2)$
                \State \quad $\alpha^{(l)} \sim \mathcal{N}(\mu_{\alpha}, \sigma_{\alpha}^2)$
                \State Apply diode activation function:
                \State \quad $a_i^{(l), 0} = f_{\text{diode}}(z_i^{(l)}; \alpha^{(l)}, V_{\text{th}}^{(l)})$
                \State Compute IR drop attenuation factor:
                \State \quad Compute $\gamma^{(l)}$ based on Eq.~\eqref{eq:attenuation_factor} using estimated currents and resistances
                \State Apply attenuation due to IR drop:
                \State \quad $a_i^{(l)} = \gamma^{(l)} a_i^{(l), 0}$
            \EndFor
            \State \textbf{Backward Propagation}:
            \State Compute loss $\mathcal{L}$ using $\mathcal{L}_{\text{cls}}$
            \State Compute gradient of loss w.r.t. output activation:
            \State \quad $\delta_i^{(L)} = \frac{\partial \mathcal{L}_{\text{cls}}}{\partial a_i^{(L)}}$
            \For{each layer $l$ from $L$ down to $1$}
                \State Compute derivative of activation function:
                \State \quad $f_{\text{diode}}'(z_i^{(l)}) = \begin{cases}
                0, & z_i^{(l)} \leq V_{\text{th}}^{(l)} \\
                \alpha^{(l)}, & z_i^{(l)} > V_{\text{th}}^{(l)}
                \end{cases}$
                \State Compute error term:
                \State \quad $\delta_i^{(l)} = \gamma^{(l)} f_{\text{diode}}'(z_i^{(l)}) \left( \sum_{k} w_{ik}^{(l+1)} \delta_k^{(l+1)} \right)$
                \State Accumulate gradients:
                \State \quad $\Delta w_{ij}^{(l)} \mathrel{+}= a_j^{(l-1)} \delta_i^{(l)}$
                \State \quad $\Delta b_i^{(l)} \mathrel{+}= \delta_i^{(l)}$
            \EndFor
        \EndFor
        \State \textbf{Update Weights and Biases}:
        \For{each layer $l$}
            \State Update weights and biases:
            \State \quad $w_{ij}^{(l)} \leftarrow w_{ij}^{(l)} - \eta \left( \frac{1}{N_{\text{batch}}} \Delta w_{ij}^{(l)} + \lambda_w w_{ij}^{(l)} \right)$
            \State \quad $b_i^{(l)} \leftarrow b_i^{(l)} - \eta \left( \frac{1}{N_{\text{batch}}} \Delta b_i^{(l)} \right)$
        \EndFor
    \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}