\chapter{Introduction}
\label{ch:intro}

% Opening Hook - Concrete Scenario
Deep in the Amazon rainforest, fifty thousand camera traps stand sentinel across an area larger than France, tasked with an impossible mission: monitoring the world's most biodiverse ecosystem while operating without power infrastructure, without network connectivity, and without human maintenance for decades. Each device must capture and analyze thousands of images daily, distinguish jaguars from shadows, detect illegal logging activities in real-time, and coordinate with neighboring sensors---all while harvesting mere microwatts from filtered sunlight beneath the forest canopy. This is not science fiction but an urgent reality. As climate change accelerates and biodiversity collapses at unprecedented rates, our ability to monitor and protect critical ecosystems depends on deploying intelligent sensors at a scale that defies conventional computing paradigms. The Amazon deployment represents just one instance of a fundamental challenge reshaping computing: how do we bring artificial intelligence to the trillions of devices that will operate beyond the reach of power grids, beyond reliable networks, and beyond human maintenance? This dissertation presents a radical answer---we must abandon our most basic assumption about computing infrastructure and embrace intermittency not as a limitation to overcome but as a defining characteristic of sustainable, planet-scale intelligence.

\section{The Crisis of Scale}
\label{sec:intro:crisis}

The magnitude of edge computing's expansion defies conventional infrastructure approaches. By 2025, over thirty billion IoT devices will generate 79.4 zettabytes of data annually~\cite{Cisco-report}, with projections reaching one hundred billion devices by 2030. This exponential growth creates multiple intersecting crises that threaten the viability of traditional computing models. Consider first the battery apocalypse: if each of these thirty billion devices requires annual battery replacement---a conservative estimate given typical lithium battery lifespans---humanity must manufacture, distribute, install, and dispose of eighty-two million batteries every single day. The economic burden alone reaches \$2.3 billion annually in replacement costs, not accounting for the labor required to physically access devices deployed in remote locations, hazardous industrial environments, or embedded within critical infrastructure. A single smart agriculture deployment across Iowa's farmland might require replacing batteries in one million soil sensors scattered across 56,000 square miles---a logistical impossibility that would cost more than the entire annual crop value.

The environmental impact proves even more catastrophic. Manufacturing these batteries requires extracting 1.5 million tons of lithium annually, devastating ecosystems from the Atacama Desert to Tibet's sacred lakes. The resulting electronic waste stream adds 2.8 million tons of toxic materials yearly to landfills, where battery chemicals leach into groundwater and soil. The carbon footprint of battery production, transportation, and disposal contributes 18.2 million tons of CO$_2$ equivalent emissions annually---comparable to the entire nation of Sri Lanka. Meanwhile, 759 million people worldwide lack access to electricity, yet we propose deploying intelligent sensors in these same underserved regions, creating a technological paradox where advanced computing coexists with basic infrastructure absence. The human cost extends beyond environmental damage: in the Democratic Republic of Congo, where 70\% of the world's cobalt for batteries is mined, forty thousand children work in hazardous conditions to feed our insatiable demand for portable power~\cite{unicef-cobalt}.

The maintenance impossibility becomes apparent when we examine real-world deployments at scale. The Great Barrier Reef monitoring network requires underwater sensors across 344,000 square kilometers of ocean. Antarctic research stations need weather monitoring across fourteen million square kilometers of ice sheet. Smart city initiatives envision millions of sensors embedded in roads, bridges, buildings, and infrastructure---imagine maintenance crews accessing sensors inside concrete bridge pillars or beneath busy highways. Industrial IoT deployments in oil refineries, chemical plants, and nuclear facilities place sensors in environments where human access requires extensive safety protocols, specialized equipment, and planned shutdowns costing millions per day. Even seemingly accessible deployments become impractical at scale: maintaining smart streetlights across Los Angeles requires servicing 220,000 units spread across 503 square miles of urban terrain. The traditional model of battery-powered operation with periodic maintenance collapses under the weight of these numbers, demanding a fundamental rethinking of how we power and sustain edge intelligence.

\section{The Intermittent Computing Revolution}
\label{sec:intro:revolution}

The intermittent computing paradigm challenges the foundational assumption underlying all modern computing systems: that somewhere, somehow, there exists a power socket. Every device from smartphones to satellites ultimately assumes access to reliable power, whether through direct connection or battery storage that gets periodically recharged. Even our most power-conscious designs merely optimize consumption rates while maintaining this core dependency on continuous electrical infrastructure. Intermittent computing shatters this assumption entirely, acknowledging that for the vast majority of future computing devices, there will never be a power socket, never be a battery replacement, never be a maintenance visit. Instead, these systems must operate indefinitely using only energy scavenged from their immediate environment---a few microwatts from indoor light, milliwatts from vibrations, sporadic bursts from radio waves. This shift from fighting intermittency to embracing it represents more than a technical evolution; it demands reconceptualizing computation itself as a fundamentally discontinuous process where forward progress occurs in brief moments between extended failures, where memory persistence matters more than processing speed, and where graceful degradation replaces guaranteed completion.

The revolution extends far beyond power intermittency alone. Modern computing systems face multiple forms of intermittency that traditional architectures cannot address. Network connectivity intermittency plagues rural deployments, mobile systems, and satellite communications, where devices experience hours or days without communication opportunities. A agricultural sensor network in rural Kenya might achieve connectivity only when a drone flies overhead weekly, while ocean monitoring buoys lose satellite contact during storms precisely when their data becomes most critical. Hardware availability intermittency affects cloud computing through spot instances that terminate without warning, shared GPU clusters where accelerators become unavailable mid-computation, and edge servers where thermal constraints force dynamic frequency scaling. Even in data centers, hardware intermittency manifests through resource contention, where deep learning training jobs compete for limited GPU memory, forcing constant checkpointing and migration. The complete intermittent computing stack must therefore handle not just power variations but also network disconnections, hardware disappearances, and resource fluctuations as normal operating conditions rather than exceptional failures.

Energy harvesting technologies offer compelling capabilities but introduce fundamental unpredictability into system operation. Solar cells generate 100 $\mu$W/cm$^2$ indoors but 100 mW/cm$^2$ in direct sunlight---a thousand-fold variation that occurs multiple times daily. Piezoelectric harvesters produce 10-500 $\mu$W from human motion but nothing during rest periods. Thermal generators extract 20-40 $\mu$W/cm$^2$ from body heat but cease functioning when ambient temperatures equalize. RF harvesters scavenge 1-100 $\mu$W from ambient radio waves with availability dependent on unpredictable transmission patterns. These energy sources cannot be controlled, predicted with precision, or stored efficiently in batteries without defeating the maintenance-free objective. The evolution of intermittent computing from 2011's first checkpointing systems through 2024's neural network accelerators reveals how the field has progressed from merely surviving power failures to actively exploiting them. Early systems like Mementos~\cite{mementos} focused on preserving program state across power cycles. The 2015 introduction of task-based programming models like Chain~\cite{chain} enabled compositional program construction. By 2018, systems like Capybara~\cite{capybara} demonstrated reconfigurable energy storage, while 2020's Botoks~\cite{botoks} brought batteryless operation to commodity hardware. Today's systems achieve complex applications like machine learning inference, cryptographic protocols, and distributed coordination despite frequent power failures.

Realizing intermittent computing's potential requires a complete full-stack approach that transcends traditional abstraction boundaries. This is emphatically not just a software problem that can be solved with clever checkpointing algorithms, nor merely a hardware challenge requiring better energy harvesters or non-volatile memories. Instead, breakthrough capabilities emerge only through coordinated co-design across every layer of the computing stack. At the circuit level, novel analog computing elements and processing-in-memory architectures minimize energy per operation. The hardware layer provides adaptive voltage scaling, heterogeneous processing units, and hybrid volatile/non-volatile memory hierarchies. System software manages task scheduling, memory allocation, and peripheral coordination under varying energy budgets. Runtime systems handle checkpointing, forward progress guarantees, and consistency management. Algorithms must be redesigned for incremental execution, partial results, and graceful degradation. Applications need to expose semantic information enabling system-level optimizations. This full-stack co-design distinguishes intermittent computing from traditional power management, creating synergies where optimizations at each layer amplify rather than constrain possibilities at others. The intermittent computing stack fundamentally reimagines how these layers interact: circuits that expose power state to software, hardware that adapts to available energy, operating systems that schedule based on harvesting predictions, runtimes that checkpoint application-specific state, algorithms that treat interruptions as features not bugs, and applications that gracefully degrade functionality rather than failing catastrophically.

\section{Intelligence at the Edge - The New Imperative}
\label{sec:intro:intelligence}

The migration of machine learning from cloud data centers to edge devices represents an inevitable technological transformation driven by fundamental physical and economic constraints. Privacy regulations like GDPR and CCPA increasingly prohibit transmitting raw sensor data to cloud services, particularly for healthcare, biometric, and behavioral applications. Latency requirements for autonomous vehicles, industrial control systems, and augmented reality demand sub-millisecond response times impossible with cloud round-trips. Bandwidth limitations become insurmountable when considering computer vision applications: a single 1080p camera generates 6 Mbps of raw data, meaning a thousand-camera smart city deployment would require 6 Gbps continuous upstream bandwidth---economically infeasible and physically impossible in many deployments. The energy cost of communication dwarfs computation for many edge AI tasks. Transmitting one megabyte of data over cellular networks consumes 3000 millijoules, while performing one million multiply-accumulate operations on modern embedded processors requires only 10 millijoules---a 300$\times$ difference that makes local processing imperative for battery-powered devices. Security concerns multiply when data traverses public networks, creating attack surfaces for adversaries to intercept, modify, or inject malicious information. Edge intelligence eliminates these vulnerabilities by keeping sensitive data local, processing it where it originates, and transmitting only high-level insights or decisions.

The quantitative analysis reveals the fundamental physics driving edge intelligence adoption. Shannon's capacity theorem dictates that wireless communication energy scales linearly with distance squared, while computation energy follows Moore's Law exponential improvements. This growing gap---communication becoming relatively more expensive while computation becomes cheaper---creates an inflection point where local processing becomes universally preferable. Consider a wildlife camera trap identifying species: transmitting a 2MB image over LoRa requires 8.4 joules and 140 seconds, while running MobileNet inference locally consumes 0.3 joules in 200 milliseconds---28$\times$ less energy and 700$\times$ faster. The mathematics become even more compelling for continuous monitoring applications. A industrial vibration sensor sampling at 10 kHz generates 86.4 GB daily. Cloud processing would require \$312 monthly in cellular data costs per sensor, making thousand-sensor deployments economically impossible. Local anomaly detection reduces this to a few kilobytes of daily status updates, cutting costs by 10,000$\times$. Network physics also impose hard barriers: rural areas lack connectivity entirely, underwater and underground environments block radio propagation, and RF interference in industrial settings corrupts transmissions. These fundamental constraints make edge intelligence not merely advantageous but absolutely necessary for the vast majority of future AI applications.

Yet the deep neural networks powering modern AI were designed for an entirely different computational universe. ResNet-50 requires 4 billion operations per inference, assuming gigabytes of RAM, hundreds of watts of power, and uninterrupted execution. GPT-3 demands 175 billion parameters requiring 350 GB of memory just to store the model. These architectures emerged from data centers where thousand-dollar GPUs consume 400 watts continuously, where failure means automatic retry on redundant hardware, where models train for weeks on million-dollar clusters. The mismatch between these cloud-native architectures and edge reality could not be more severe. An energy-harvesting sensor might accumulate enough power for one million operations daily---sufficient for 0.00025% of a single ResNet-50 inference. Memory constraints prove equally prohibitive: embedded microcontrollers typically provide 256 KB to 2 MB of RAM, while even "tiny" models like MobileNet require 17 MB for parameters and activations. The sequential layer-by-layer execution of DNNs creates long dependency chains incompatible with intermittent operation where any layer might fail mid-computation. Training amplifies these challenges by orders of magnitude, requiring backward passes, gradient storage, and iterative optimization over multiple epochs. The co-design opportunity lies in recognizing that neither existing ML models nor current embedded systems were designed for intermittent intelligence, creating unprecedented potential for innovation at their intersection.

\section{Thesis and Transformative Contributions}
\label{sec:intro:thesis}

This dissertation advances a bold thesis: intermittent computing systems can not only support sophisticated machine learning workloads but achieve capabilities impossible in traditional continuously powered systems by embracing a radical full-stack co-design methodology that spans from analog circuits through distributed algorithms, transforming power scarcity from a constraint into an architectural principle that drives innovation across thirteen orders of magnitude in power scale---from microwatt sensors to megawatt edge servers. This thesis challenges the conventional wisdom that resource constraints necessarily limit functionality, demonstrating instead that intermittency-aware design produces systems with superior efficiency, robustness, and scalability compared to their continuously powered counterparts. We prove this through five concrete systems that collectively establish intermittent machine learning as a new field bridging embedded systems, computer architecture, machine learning, and sustainable computing.

The journey from sensors to servers reveals how intermittent computing principles scale across the entire computing spectrum. At the microscale, Origin demonstrates distributed intelligence emerging from networks of individually limited sensors, where intermittency becomes a source of ensemble diversity rather than a reliability problem. Moving up the power scale, Seeker bridges the critical gap between intermittent sensors and powered infrastructure, solving the communication bottleneck that has prevented practical deployment of energy-harvesting systems. NExUME reconceptualizes neural network training itself, showing how models can be fundamentally redesigned for intermittent deployment rather than merely adapted post-hoc. LREyE pushes into analog computing territory, exploiting the natural alignment between approximate computing and intermittent operation to achieve efficiency gains impossible in digital systems. Finally, \US{} demonstrates that intermittent computing principles apply even to edge servers, where renewable energy variations create a different but equally important form of intermittency. This progression from microwatts to megawatts---spanning thirteen orders of magnitude in power scale---proves that intermittency-aware design represents a fundamental paradigm shift applicable across all computing scales rather than a narrow optimization for energy-harvesting sensors.

Origin establishes the theoretical and practical foundation for distributed intermittent intelligence through ensemble learning techniques that transform unreliability into robustness. The key insight is that intermittent power failures, rather than being purely detrimental, create natural diversity in ensemble members that improves generalization and reduces overfitting. Origin achieves 83.88\% accuracy on human activity recognition tasks, surpassing the 81.16\% accuracy of traditional powered systems while operating entirely on harvested energy. The system introduces activity-aware scheduling that prioritizes sensors based on task-specific relevance, reducing energy waste by 47\% compared to naive round-robin approaches. Adaptive confidence weighting accounts for varying sensor reliability, automatically adjusting ensemble votes based on historical availability patterns and current energy states. Temporal continuity exploitation through aggressive result caching reduces redundant computation by 73\% for slowly changing phenomena. These techniques combine to demonstrate that distributed intermittent systems can achieve collective intelligence exceeding any individual node's capabilities, establishing the viability of batteryless machine learning networks.

Seeker addresses the critical challenge of coordinating intermittent devices with powered infrastructure, reducing communication requirements by 8.9$\times$ while maintaining 86.8\% accuracy on complex vision tasks. The system introduces store-and-execute strategies that maximize on-sensor computation during high-energy periods, banking processed features rather than raw data for later transmission. Task-aware coreset construction creates application-specific compressions that preserve decision boundaries while discarding redundant information, achieving 50$\times$ reduction for anomaly detection tasks. Adaptive quantization dynamically adjusts precision based on available energy, using 2-bit representations during power scarcity and 8-bit when energy permits. Progressive transmission protocols ensure partial results remain useful even when communication fails mid-transfer. Seeker's innovations enable practical deployment of intermittent ML systems by solving the fundamental bottleneck of sensor-to-infrastructure communication, making thousand-node deployments economically viable for the first time.

NExUME revolutionizes neural network training by incorporating intermittency directly into the learning process, achieving 6-22\% accuracy improvements over state-of-the-art intermittent inference systems. The key innovation involves training models with dynamic dropout rates that match expected power failure patterns, creating networks robust to partial execution by design rather than accident. Energy-aware quantization during training produces models that gracefully degrade precision as power diminishes, maintaining functionality across three orders of magnitude in energy availability. Hardware-software co-design enables efficient checkpoint management with less than 5\% overhead through selective state preservation and incremental forward progress tracking. The training process itself becomes intermittency-aware, using power failures as a form of regularization that prevents overfitting while improving generalization. NExUME demonstrates that intermittency-aware training produces fundamentally different and superior models compared to standard training followed by post-hoc adaptation, establishing a new paradigm for edge AI development.

LREyE pushes the efficiency frontier through analog-digital hybrid architectures that achieve 68\% higher energy efficiency compared to pure digital implementations. The system exploits the natural alignment between analog computing's approximate operations and intermittent systems' tolerance for imprecision, using Schottky diode networks for activation functions that consume 1000$\times$ less power than digital alternatives. Analog-aware training compensates for hardware non-idealities including device mismatch, temperature drift, and aging effects, producing models robust to 15\% component variation. ReRAM-based processing-in-memory architectures eliminate data movement between memory and computation units, reducing energy consumption by 43$\times$ for matrix operations. Multi-level analog representations pack 4 bits into single devices, quadrupling effective memory density. LREyE's innovations demonstrate that intermittent systems' relaxed precision requirements enable architectural optimizations impossible in traditional digital systems, opening new frontiers in ultra-low-power AI hardware.

\US{} scales intermittent computing principles to edge server deployments powered by renewable energy, achieving 234 kWh to 2.63 MWh annual energy savings while improving model accuracy by 4.96\%. The system introduces morphable accelerator architectures that dynamically adjust computational precision, parallelism, and clock frequency based on solar power availability, maintaining forward progress despite 100$\times$ power variations throughout the day. Continuous learning algorithms robust to intermittent training enable models to adapt to changing data distributions despite unreliable power, using techniques from online learning and catastrophic forgetting prevention. System-level optimizations include predictive scheduling based on weather forecasts, load migration between intermittent and powered resources, and quality-of-service guarantees despite power uncertainty. \US{} demonstrates that intermittent computing principles apply beyond tiny sensors to substantial computing infrastructure, enabling sustainable edge analytics at scales previously requiring grid power. The system's deployment across twelve edge sites processing 400TB daily proves commercial viability while reducing carbon emissions by 847 tons annually.

\section{Scientific Foundations and Methodology}
\label{sec:intro:foundations}

The scientific methodology underlying this dissertation rests on four foundational pillars that guide our approach to intermittent machine learning system design. First, the co-design principle mandates that optimizations must span the entire computing stack rather than focusing on single layers in isolation. This principle recognizes that breakthrough efficiency emerges from synergistic interactions between hardware capabilities, system software policies, and application algorithms. Second, the embrace-don't-hide philosophy treats intermittency as a first-class design consideration rather than an exceptional condition to mask. By exposing power variations to applications and algorithms, we enable adaptive behaviors impossible in traditional systems that hide resource variations behind abstractions. Third, the collective intelligence approach leverages distributed coordination to overcome individual device limitations, recognizing that networks of simple intermittent devices can achieve emergent capabilities exceeding any single node. Fourth, the sustainability-first methodology places energy efficiency and environmental impact as primary design metrics rather than secondary optimizations, fundamentally changing how we evaluate system success.

Our experimental methodology emphasizes reproducible, real-world validation over simulation-based studies. Every system presented in this dissertation has been implemented in actual hardware and tested under realistic energy harvesting conditions. We employ custom measurement infrastructure capable of capturing power consumption at microsecond granularity while emulating various harvesting scenarios from solar to vibration sources. Our benchmarks span diverse application domains including human activity recognition, wildlife monitoring, industrial predictive maintenance, and environmental sensing to ensure broad applicability. We release all hardware designs, software implementations, and datasets to enable community verification and extension of our results. This commitment to reproducible systems research ensures that our contributions represent practical advances rather than theoretical possibilities.

The introduction of sustainability as a first-class design metric fundamentally transforms how we evaluate computing systems. Traditional metrics like performance per watt or energy-delay product assume continuous power availability and optimize for efficiency within that constraint. Intermittent systems require new metrics that capture sustainability holistically. We introduce energy-normalized accuracy that measures model performance per joule harvested rather than consumed, carbon-aware scheduling that minimizes emissions by aligning computation with renewable availability, and battery-free operation lifetime that quantifies system longevity without maintenance. These metrics reveal optimization opportunities invisible to traditional evaluation methods: a model with 2\% lower accuracy but 10$\times$ lower energy consumption might be superior for sustainability even if inferior by conventional metrics. By elevating sustainability from an afterthought to a primary design consideration, we enable computing systems that enhance rather than degrade planetary health.

\section{Broader Impact and Applications}
\label{sec:intro:impact}

The transformative potential of intermittent machine learning extends far beyond the specific systems presented in this dissertation, promising to revolutionize multiple industries facing the triple challenge of intelligence, scale, and sustainability. In predictive maintenance for Industry 4.0, intermittent sensors can monitor millions of bearings, motors, and pumps across manufacturing facilities without the wiring costs that currently limit deployment to critical equipment only. A single automotive assembly plant contains over 30,000 rotating components that could benefit from vibration monitoring, but installing powered sensors would cost \$45 million in cabling alone. Intermittent sensors powered by machine vibrations themselves eliminate this barrier, enabling comprehensive monitoring that reduces unplanned downtime by 70\% and maintenance costs by 25\%. The same principles apply to wind turbines where each blade requires hundreds of strain sensors, to railways monitoring thousands of miles of track, and to pipelines detecting leaks across continental distances. The global predictive maintenance market, valued at \$23.5 billion by 2024, could expand by 10$\times$ when freed from power infrastructure constraints.

Space exploration represents perhaps the most extreme application domain where intermittent computing becomes not merely advantageous but essential for mission success. Satellites experience power intermittency from orbital mechanics as they transition between sunlight and shadow every 90 minutes, while deep space missions face months of darkness during planetary approach. CubeSats with limited solar panel area must perform complex Earth observation tasks using mere watts of intermittent power. Mars rovers encounter dust storms that reduce solar power by 99\% for weeks, yet must maintain critical functions and resume full operation when conditions improve. The Europa Clipper mission to Jupiter's moon receives 25$\times$ less solar power than Earth-orbiting satellites, demanding new approaches to on-board intelligence. Intermittent ML enables these missions to process sensor data locally rather than transmitting raw measurements across billions of kilometers, reducing communication requirements by 1000$\times$ while enabling real-time decision making. The technology proves equally valuable for the emerging mega-constellations of communication satellites where 42,000 planned satellites cannot rely on ground-based processing for beam forming and interference management.

Mining operations in extreme environments demonstrate how intermittent computing enables intelligence where traditional infrastructure cannot reach. Underground mines extend kilometers below surface where running power cables costs \$10,000 per meter and wireless communication cannot penetrate rock strata. Intermittent sensors powered by mechanical vibrations from drilling equipment can monitor air quality, detect methane buildup, track equipment location, and predict cave-in risks without requiring electrical infrastructure. Open pit mines covering hundreds of square kilometers need slope stability monitoring to prevent landslides that kill hundreds annually, but the scale makes powered sensor networks impractical. Arctic mines operating at -50Â°C face battery failures that render traditional monitoring systems useless, while intermittent systems harvest energy from temperature differentials between equipment and environment. The mining industry's \$1.7 trillion annual revenue depends increasingly on accessing deeper, more remote deposits where intermittent computing becomes the only viable approach for ensuring worker safety and operational efficiency.

Disaster response and emergency systems showcase intermittent computing's resilience when traditional infrastructure fails catastrophically. Earthquakes, hurricanes, and floods routinely destroy power grids and communication networks precisely when sensing and coordination become most critical. Intermittent sensors embedded in buildings can continue structural health monitoring after earthquakes using energy harvested from aftershock vibrations, guiding rescue efforts to survivors and warning of imminent collapses. Flood monitoring networks powered by water flow itself provide real-time data when electrical infrastructure becomes submerged. Forest fire detection systems running on thermal gradients operate indefinitely in remote wilderness areas, providing early warning that can prevent megafires causing billions in damage. Emergency communication beacons powered by body heat enable search and rescue operations when batteries fail in extreme cold. The resilience of intermittent systems---their ability to operate despite infrastructure failure---transforms disaster response from reactive to proactive, saving lives and property.

Environmental monitoring at planetary scale becomes economically feasible only through intermittent computing's elimination of maintenance requirements. Climate scientists need millions of sensors to understand carbon cycling, ocean acidification, and ecosystem responses to warming, but current powered sensors cost \$500-5000 each with \$200 annual maintenance. Intermittent sensors costing under \$10 could blanket forests, oceans, and atmosphere with unprecedented measurement density. Coral reef monitoring across 284,300 square kilometers of global reefs requires underwater sensors that currently need monthly battery replacement by divers---economically and logistically impossible at scale. Agricultural optimization demands soil moisture, nutrient, and microbiome monitoring across Earth's 1.5 billion hectares of cropland to optimize irrigation and reduce fertilizer runoff causing ocean dead zones. Smart agriculture could reduce water usage by 30\% and fertilizer application by 40\%, but only if sensors become truly maintenance-free. The environmental sensing market projected to reach \$2.3 billion addresses only a tiny fraction of measurement needs due to power constraints that intermittent computing eliminates.

The democratization of computation through intermittent systems enables intelligence in regions and applications where traditional computing cannot reach. The 759 million people without electricity access gain the ability to deploy smart sensors for water quality monitoring, agricultural optimization, and health tracking without requiring electrical infrastructure that may never arrive. Developing nations leapfrog traditional infrastructure by deploying intermittent intelligence directly, just as mobile phones bypassed landlines. Indigenous communities can monitor their lands for illegal logging and poaching without depending on government infrastructure. Citizen scientists gain access to sophisticated environmental monitoring capabilities previously restricted to well-funded research institutions. The elimination of battery replacement democratizes not just deployment but maintenance, enabling community-managed sensor networks in regions where technical expertise remains scarce. This democratization extends to cost structures: when sensors cost dollars rather than hundreds and operate indefinitely without maintenance, communities, schools, and individuals can deploy intelligence at scales previously restricted to corporations and governments.

\section{Dissertation Organization}
\label{sec:intro:organization}

This dissertation unfolds as a carefully orchestrated journey from establishing fundamental capabilities through achieving sophisticated system-level integration, with each chapter building upon previous foundations while advancing toward the ultimate goal of sustainable, scalable machine learning at the edge. The progression reflects both the historical evolution of the field and the logical dependencies between contributions, ensuring readers can follow the narrative whether approaching from systems, architecture, machine learning, or sustainability perspectives. The structure deliberately alternates between breakthrough innovations and practical integrations, between theoretical advances and experimental validations, creating a rhythm that maintains intellectual engagement while providing concrete evidence of real-world impact.

Chapter~\ref{ch:intelligent-inference} establishes the intellectual foundations by surveying three converging fields: intermittent computing's evolution from simple checkpointing to complex applications, edge machine learning's migration from cloud to embedded devices, and energy harvesting's maturation from laboratory curiosities to practical power sources. This chapter equips readers with essential background while identifying the key limitations and open challenges that motivate our research contributions. We trace intermittent computing's development from 2011's Mementos through today's neural network accelerators, analyze why existing ML models fail under power constraints, and quantify energy harvesting's capabilities and limitations across different sources and environments.

Chapter~\ref{ch:intelligent-inference} introduces Origin, our foundational system that proves distributed intermittent devices can successfully perform machine learning inference through carefully orchestrated ensemble learning. This chapter establishes core techniques used throughout the dissertation: exploiting temporal continuity in sensor data, managing distributed coordination without reliable communication, and achieving collective intelligence from individually limited devices. Origin's demonstration that intermittent systems can exceed continuously powered alternatives' accuracy while eliminating batteries provides the existence proof necessary for all subsequent work.

Chapter~\ref{ch:intelligent-inference} presents Seeker, which solves the critical bottleneck preventing practical deployment of intermittent ML systems: efficient communication between energy-harvesting sensors and powered infrastructure. By developing task-aware compression, adaptive quantization, and progressive transmission protocols, Seeker reduces communication overhead by nearly 10$\times$ while maintaining model accuracy. This chapter bridges the gap between isolated intermittent devices and integrated systems, enabling the thousand-node deployments necessary for real-world applications.

Chapter~\ref{ch:nexume} revolutionizes the training process itself through NExUME, demonstrating that neural networks designed explicitly for intermittent deployment significantly outperform standard models adapted post-hoc. By incorporating power failure patterns directly into training through dynamic dropout and energy-aware quantization, NExUME produces models that gracefully degrade rather than catastrophically fail when energy diminishes. This chapter establishes that intermittency-aware training represents a new paradigm in edge AI development, not merely an optimization technique.

Chapter~\ref{ch:lreye} explores the hardware frontier through LREyE, pushing efficiency boundaries by exploiting analog computing's natural alignment with intermittent operation's tolerance for approximation. Using processing-in-memory architectures, Schottky diode activation functions, and analog-aware training algorithms, LREyE achieves efficiency gains impossible in purely digital systems. This chapter demonstrates that intermittent systems' relaxed precision requirements enable architectural innovations that redefine the efficiency frontier for edge AI hardware.

Chapter~\ref{ch:usas} scales our techniques to edge server deployments through \USS, proving that intermittent computing principles apply across thirteen orders of magnitude in power scale. By developing morphable accelerators that adapt to renewable energy variations and continuous learning algorithms robust to power interruptions, \US enables sustainable edge analytics at commercially relevant scales. This chapter's demonstration of megawatt-hour energy savings while improving model accuracy validates intermittent computing's relevance beyond tiny sensors.

Chapter~\ref{chapter8:conclusions} synthesizes lessons learned across all systems to outline a research agenda for the emerging field of intermittent machine learning. We identify open challenges in programming models, hardware architectures, distributed algorithms, and application domains while proposing concrete next steps for the research community. This forward-looking chapter ensures the dissertation's impact extends beyond specific contributions to inspire continued innovation.

Chapter~\ref{chapter8:conclusions} concludes by reflecting on the broader implications of this work for sustainable computing, artificial intelligence, and humanity's relationship with technology. We argue that intermittent computing represents not merely a technical solution to power constraints but a philosophical shift toward computing systems that enhance rather than degrade planetary health. The chapter connects our technical contributions to larger questions about technology's role in addressing climate change, inequality, and sustainability.

Readers approaching this dissertation from different backgrounds may benefit from alternative reading paths. Systems researchers should begin with Chapters~\ref{ch:intelligent-inference} for distributed systems contributions before proceeding to~\ref{ch:usas} for architectural innovations. Machine learning practitioners will find Chapters~\ref{ch:nexume} and~\ref{ch:intelligent-inference} most relevant for algorithmic advances, with~\ref{ch:lreye} providing hardware context. Hardware designers should focus on Chapters~\ref{ch:lreye} and~\ref{ch:usas} for circuit and architecture contributions, using~\ref{ch:intelligent-inference} for necessary software context. Sustainability researchers can start with Chapters~\ref{ch:usas} and~\ref{chapter8:conclusions} for environmental impact analysis before diving into technical details. Application developers seeking practical deployment guidance should prioritize Chapters~\ref{ch:intelligent-inference}, and the case studies throughout. Each chapter maintains sufficient self-containment for independent reading while contributing to the unified narrative of enabling intelligence under extreme constraints.

As we stand at the confluence of the climate crisis and the intelligence revolution, the question is not whether computing must become sustainable but how quickly we can achieve this transformation. This dissertation provides concrete answers through systems that turn energy scarcity from limitation into opportunity, demonstrating that the path to truly intelligent edge computing runs directly through intermittency. The journey from sensors to servers, from microwatts to megawatts, from surviving power failures to exploiting them reveals that sustainable computing is not about doing less with less but about doing more with different. By embracing intermittency as a fundamental design principle rather than fighting it as an inconvenience, we unlock possibilities for intelligence at scales and in locations that traditional approaches cannot reach. The implications extend beyond the billion devices waiting for intelligence to the billion people waiting for computation, beyond the specific systems we build to the sustainable future we enable. This is the promise of intermittent computing: not merely surviving without power but thriving because of its absence, not merely reducing environmental impact but reversing it, not merely enabling edge intelligence but democratizing it. The revolution begins with accepting a simple but radical truth---there is no power socket, there never was, and there never needs to be.